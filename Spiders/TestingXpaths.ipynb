{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example of how I find data that the xpaths have\n",
    "# This example is for Russ Market Spider\n",
    "# Imports for Scraping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service as FirefoxService\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from os import path\n",
    "import time\n",
    "\n",
    "#Use this and edit this to extract data from the xpaths \n",
    "#Creators Note: if any major changes that are made you need to update the spiders javascriptXpath function since \n",
    "#this is the exact function that the spider uses to collect data from the url\n",
    "def javascriptXpath (driver, xpath):\n",
    "    try: \n",
    "        # Waits for page to load \n",
    "        ignored_exceptions=(NoSuchElementException,StaleElementReferenceException)\n",
    "        elements = WebDriverWait(driver, waitTime, ignored_exceptions=ignored_exceptions).until(EC.presence_of_all_elements_located((By.XPATH, xpath)))\n",
    "        # A set of all the outputs that we want to avoid\n",
    "        invalidOutputs = {\"error\", 'skip' \"$nan\", ''}\n",
    "        loopCount = 0\n",
    "        # Runs the javascript and collects the text data from the inputed xpath\n",
    "        # We want to keep repeating if we get '' becasue the page is still loading\n",
    "        while loopCount < loopRepeat:\n",
    "            #Running the JavaScript\n",
    "            text = driver.execute_script(\"\"\"\n",
    "                const element = document.evaluate(arguments[0], document, null, XPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue;\n",
    "                if (!element) {\n",
    "                    return 'skip';\n",
    "                }\n",
    "                return element.textContent.trim();\n",
    "            \"\"\", xpath)\n",
    "            checkText = text.replace(\" \", \"\").lower()\n",
    "            if checkText in invalidOutputs:\n",
    "                loopCount+=1\n",
    "            else:\n",
    "                print(loopCount, \"xpath attempts for (\", text, \")\")\n",
    "                break\n",
    "        if loopCount < loopRepeat:\n",
    "            print(\"Success for \" ,xpath)         \n",
    "        else: \n",
    "            return \"xpath value not found\"\n",
    "        return text\n",
    "    except TimeoutException:\n",
    "        # This means the xpath wasn't found in the page\n",
    "        print('Could not find xpath for: ', xpath)\n",
    "        return 'Empty'\n",
    "\n",
    "#Add test and fix xpaths here. Use multiple urls for testing  \n",
    "def testXpaths(url):\n",
    "    driver.get(url)\n",
    "    nameXpath = '//*[@id=\"page-title\"]//h1[contains(@class,\"fp-page-header fp-page-title\")]'\n",
    "    print(javascriptXpath(driver, nameXpath))\n",
    "    priceXpath = '//*[@id=\"page-title\"]//*[contains(@class,\"fp-item-price\")]/span[contains(@class,\"fp-item-base-price\")]'\n",
    "    print(javascriptXpath(driver, priceXpath))\n",
    "    weightXpath = '//*[@id=\"page-title\"]//*[contains(@class,\"fp-item-price\")]/span[contains(@class,\"fp-item-size\")]' \n",
    "    print(javascriptXpath(driver, weightXpath))\n",
    "    saleXpath = '//*[@id=\"page-title\"]//*[contains(@class,\"fp-item-sale\")]/span[contains(@class,\"fp-item-sale-date\")]/strong' #optional\n",
    "    print(javascriptXpath(driver, saleXpath))\n",
    "\n",
    "# setup\n",
    "waitTime = 10\n",
    "driver = webdriver.Firefox(service=FirefoxService(GeckoDriverManager().install(), log_path=path.devnull))\n",
    "storeLocationUrl = 'https://www.russmarket.com/shop#!/?store_id=6158'\n",
    "driver.get(storeLocationUrl)\n",
    "time.sleep(5)\n",
    "print(\"Store location set\")\n",
    "loopRepeat = 100\n",
    "\n",
    "# Successful tests\n",
    "url = \"https://www.russmarket.com/shop/produce/fresh_vegetables/tomatoes/heirloom_tomatoes/p/12412\"\n",
    "testXpaths(url)\n",
    "# Successful tests\n",
    "url = \"https://www.russmarket.com/shop/meat/bacon/prairie_fresh_signature_applewood_smoked_bacon_pork_loin_filet_27_2_oz/p/6828650\"\n",
    "testXpaths(url)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example of how I find data that the xpaths have\n",
    "# This example is for New Pioneer Co-op\n",
    "# Imports for Scraping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service as FirefoxService\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from os import path\n",
    "import time\n",
    "\n",
    "#Use this and edit this to extract data from the xpaths \n",
    "#Creators Note: if any major changes that are made you need to update the spiders javascriptXpath function since \n",
    "#this is the exact function that the spider uses to collect data from the url\n",
    "def javascriptXpath (driver, xpath):\n",
    "    try: \n",
    "        # Waits for page to load \n",
    "        ignored_exceptions=(NoSuchElementException,StaleElementReferenceException)\n",
    "        elements = WebDriverWait(driver, waitTime, ignored_exceptions=ignored_exceptions).until(EC.presence_of_all_elements_located((By.XPATH, xpath)))\n",
    "        # A set of all the outputs that we want to avoid\n",
    "        invalidOutputs = {\"error\", 'skip' \"$nan\", ''}\n",
    "        loopCount = 0\n",
    "        # Runs the javascript and collects the text data from the inputed xpath\n",
    "        # We want to keep repeating if we get '' becasue the page is still loading\n",
    "        while loopCount < loopRepeat:\n",
    "            #Running the JavaScript\n",
    "            text = driver.execute_script(\"\"\"\n",
    "                const element = document.evaluate(arguments[0], document, null, XPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue;\n",
    "                if (!element) {\n",
    "                    return 'skip';\n",
    "                }\n",
    "                return element.textContent.trim();\n",
    "            \"\"\", xpath)\n",
    "            checkText = text.replace(\" \", \"\").lower()\n",
    "            if checkText in invalidOutputs:\n",
    "                loopCount+=1\n",
    "            else:\n",
    "                print(loopCount, \"xpath attempts for (\", text, \")\")\n",
    "                break\n",
    "        if loopCount < loopRepeat:\n",
    "            print(\"Success for \" ,xpath)         \n",
    "        else: \n",
    "            return \"xpath value not found\"\n",
    "        return text\n",
    "    except TimeoutException:\n",
    "        # This means the xpath wasn't found in the page\n",
    "        print('Could not find xpath for: ', xpath)\n",
    "        return 'Empty'\n",
    "\n",
    "#Add test and fix xpaths here. Use multiple urls for testing  \n",
    "def testXpaths(url):\n",
    "    driver.get(url)\n",
    "    nameXpath = '//*[@id=\"products\"]//*[contains(@class,\"fp-item-detail\")]//*[contains(@class,\"fp-item-name\")]'\n",
    "    print(javascriptXpath(driver, nameXpath))\n",
    "    priceXpath = '//*[@id=\"products\"]//*[contains(@class,\"fp-item-detail\")]//*[contains(@class,\"fp-item-price\")]//span[contains(@class,\"fp-item-base-price\")]'\n",
    "    print(javascriptXpath(driver, priceXpath))\n",
    "    weightXpath = '//*[@id=\"products\"]//*[contains(@class,\"fp-item-detail\")]//*[contains(@class,\"fp-item-price\")]//span[contains(@class,\"fp-item-size\")]'\n",
    "    print(javascriptXpath(driver, weightXpath))\n",
    "    saleXpath = '//*[@id=\"products\"]//*[contains(@class,\"fp-item-detail\")]//*[contains(@class,\"fp-item-sale\")]//span[contains(@class,\"fp-item-sale-price\")]' # optional\n",
    "    print(javascriptXpath(driver, saleXpath))\n",
    "\n",
    "driver = webdriver.Firefox(service=FirefoxService(GeckoDriverManager().install(), log_path=path.devnull))\n",
    "url = \"https://shop.newpi.coop/shop/meat/bacon/sliced/applegate_natural_hickory_smoked_uncured_sunday_bacon_8_oz/p/19959#!/?department_id=1322093\"\n",
    "testXpaths(url)\n",
    "\n",
    "url = 'https://shop.newpi.coop/shop/just_ice_tea_green_tea_original_unsweetened_16_fl_oz/p/1564405684713463723'\n",
    "testXpaths(url)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSPG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
