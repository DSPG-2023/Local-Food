{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://www.russmarket.com/shop#!/?store_id=6158/?q=Heirloom Tomatoes\n",
    "\n",
    "\n",
    "https://www.russmarket.com/shop/bakery/d/22508085#!/\n",
    "https://www.russmarket.com/shop/bakery/d/22508085#!/?store_id=6151#!/?store_id=6158#!/?store_id=6158\n",
    "\n",
    "\n",
    "https://www.russmarket.com/shop#!/?store_id=6158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "#Imports\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "#Imports for Scraping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service as FirefoxService\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "from os import path\n",
    "\n",
    "#this is for trying to grab element data \n",
    "def scriptdataWait():\n",
    "        #rendering the element\n",
    "        ignored_exceptions=(NoSuchElementException,StaleElementReferenceException,)\n",
    "        element = WebDriverWait(driver, 20, ignored_exceptions=ignored_exceptions).until(EC.presence_of_all_elements_located((By.XPATH, \"/html/body/div[1]/div/div[3]/div/section/article/section/div[5]/div[1]/div/div/div[1]\")))\n",
    "        #grabbing from script\n",
    "        data = driver.execute_script(\"return window.getComputedStyle(arguments[0],':before').getPropertyValue('content')\", \n",
    "                                      driver.find_element(By.CSS_SELECTOR, \"h1.fp-page-header\")).strip('\"')\n",
    "        print(data)\n",
    "        return data\n",
    "\n",
    "\n",
    "#setup\n",
    "url = \"https://www.russmarket.com/shop/produce/fresh_vegetables/tomatoes/heirloom_tomatoes/p/12412\"\n",
    "driver = webdriver.Firefox(service=FirefoxService(GeckoDriverManager().install(), log_path=path.devnull))\n",
    "storeLocationUrl = 'https://www.russmarket.com/shop#!/?store_id=6158'\n",
    "driver.get(storeLocationUrl)\n",
    "time.sleep(5)\n",
    "driver.get(url)\n",
    "\n",
    "print(scriptdataWait())\n",
    "\n",
    "driver.close()\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from enum import Enum\n",
    "#Imports for Scraping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service as FirefoxService\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from os import path\n",
    "import time\n",
    "\n",
    "#This class is here so that we can expand to differnet products easier make the spider \n",
    "#more dynamic and expandable\n",
    "class Products(Enum):\n",
    "    #Name = Index, URL list\n",
    "    Bacon = 1,['']\n",
    "    \n",
    "    Eggs = 2,['']\n",
    "    \n",
    "    HeirloomTomatoes = 3,['url = \"https://www.russmarket.com/shop/produce/fresh_vegetables/tomatoes/heirloom_tomatoes/p/12412\"']\n",
    "\n",
    "    Test = 4, ['https://www.russmarket.com/shop/produce/fresh_vegetables/tomatoes/heirloom_tomatoes/p/12412']\n",
    "\n",
    "\n",
    "\n",
    "class RussMarketSpider():\n",
    "    name = \"Russ Market Spider\"\n",
    "    baconFrame = pd.DataFrame(columns=['Bacon', 'Current Price', 'Sale', 'Weight', 'Url'])\n",
    "    eggFrame = pd.DataFrame(columns=['Egg', 'Current Price', 'Sale', 'Amount', 'Url'])\n",
    "    tomatoFrame = pd.DataFrame(columns=['Heirloom Tomato', 'Current Price', 'Sale', 'Weight', 'Url'])\n",
    "    testFrame = pd.DataFrame(columns=['test'])\n",
    "    spiderLogs = []\n",
    "\n",
    "    #These are methods that are available for your convences\n",
    "    def log(self, *args):\n",
    "        self.spiderLogs.append(('Logger:', args))\n",
    "        if self.LOGGER:\n",
    "            print('Logger:', *args)\n",
    "\n",
    "    def debug(self, *args):\n",
    "        self.spiderLogs.append(('Debug:', args))\n",
    "        if self.DEBUGGER:\n",
    "            print('Debug:', *args)\n",
    "    \n",
    "    def printer(self, *args):\n",
    "        self.spiderLogs.append(('Printer:', args))\n",
    "        print(*args)\n",
    "    \n",
    "    def printLogs(self):\n",
    "        print(\"\\n< --- Printing Logs --- >\\n\")\n",
    "        for entry in self.spiderLogs:\n",
    "            print(*entry)\n",
    "\n",
    "    def Logs_to_file(self, filename):\n",
    "        with open(filename, 'w') as file:\n",
    "            for log_entry in self.spiderLogs:\n",
    "                file.write('{} {}\\n'.format(log_entry[0], log_entry[1]))\n",
    "\n",
    "    def __init__(self):\n",
    "        self.DEBUGGER = False #The debugger switch to see whats going on. The Default is False\n",
    "        self.LOGGER = False #When you need to see everything that happends. The Default is False\n",
    "        self.attempts = 3 #The number of attempts the spider can retry if an error occurs. Default is 3\n",
    "        self.waitTime = 10 #The number of seconds WebDriver will wait. Default is 10\n",
    "        self.count = 0 #This saves the location of the url we are going through\n",
    "        self.runTime = 0 #Total time of extractions\n",
    "        self.totalRecoveries = 0 #Number of recoveries made while running\n",
    "        #Selenium needs a webdriver to work. I chose Firefox however you can do another if you need too\n",
    "        self.driver = webdriver.Firefox(service=FirefoxService(GeckoDriverManager().install(), log_path=path.devnull))\n",
    "        self.log(\"Driver started\")    \n",
    "\n",
    "    def restart(self):\n",
    "        self.driver.close()\n",
    "        self.driver.quit()\n",
    "        self.driver = webdriver.Firefox(service=FirefoxService(GeckoDriverManager().install(), log_path=path.devnull))\n",
    "        self.log(\"Driver restarted\")\n",
    "        self.setStoreLocation()\n",
    "\n",
    "    def setStoreLocation(self):\n",
    "        storeLocationUrl = 'https://www.russmarket.com/shop#!/?store_id=6158'\n",
    "        self.driver.get(storeLocationUrl)\n",
    "    \n",
    "    def forceQuit(self):\n",
    "        self.printer(\"Browser window was closed by user. Stopping program\")\n",
    "        self.log('\\n < --- Total runtime took %s seconds with %d recoveries --- >' % (time.time() - self.runTime, self.totalRecoveries))\n",
    "        self.Logs_to_file(self.name + ' Logs.txt')\n",
    "        self.driver.quit()\n",
    "\n",
    "    def requestExtraction(self, productType):\n",
    "        self.count = 0\n",
    "        errors = 0\n",
    "        extractionType = productType.value[0]\n",
    "        start = time.time()\n",
    "        for trying in range(self.attempts):\n",
    "            try:\n",
    "                if extractionType == 1:\n",
    "                    self.requestBacon()\n",
    "                elif extractionType == 2:\n",
    "                    self.requestEgg()\n",
    "                elif extractionType == 3:\n",
    "                    self.requestHeirloomTomatoes()\n",
    "                # Add elif for more products here\n",
    "                elif extractionType == 4:\n",
    "                    self.requestTest()\n",
    "                else:\n",
    "                    self.debug(\"An error extractionType for \" + str(extractionType) + \" has occured\")\n",
    "                self.debug(productType.name + \" Finished\")    \n",
    "                self.log('\\n< --- ' + productType.name + ' scrape took %s seconds with %d recoveries --- >\\n' % ((time.time() - start), errors))\n",
    "                self.totalRecoveries += errors\n",
    "                return self.totalRecoveries\n",
    "            # except WebDriverException:\n",
    "            #     self.forceQuit()\n",
    "            #     return None\n",
    "            except Exception as e:\n",
    "                errors += 1\n",
    "                self.debug(\"An error occurred:\", e)\n",
    "                self.debug(\"Recovering extraction and continueing\")\n",
    "                self.restart() \n",
    "        self.debug(productType.name + \" Did not Finished after \" + str(self.attempts) + \" Time wasted: %s seconds\" % (time.time() - start))\n",
    "        self.totalRecoveries += errors\n",
    "        return self.totalRecoveries\n",
    "\n",
    "    def start_requests(self):\n",
    "        self.setStoreLocation()\n",
    "        result = self.requestExtraction(Products.Test)\n",
    "        if(result == None): return\n",
    "        self.driver.close()\n",
    "        self.driver.quit()\n",
    "\n",
    "    # def start_requests( self ):\n",
    "    #     self.runTime = time.time()\n",
    "    #     self.totalRecoveries = 0 \n",
    "    #     result = self.requestExtraction(Products.Bacon)\n",
    "    #     if(result == None): return\n",
    "    #     result = self.requestExtraction(Products.Eggs)\n",
    "    #     if(result == None): return\n",
    "    #     result = self.requestExtraction(Products.HeirloomTomatoes)\n",
    "    #     if(result == None): return\n",
    "    #     self.driver.close()\n",
    "    #     self.driver.quit()\n",
    "    #     #Adds the date that the data was scraped\n",
    "    #     currentDate = str(datetime(datetime.today().year, datetime.today().month, datetime.today().day))[:-8]\n",
    "    #     self.log(\"Exporting files\")\n",
    "    #     #Dataframes to CSV files\n",
    "    #     self.baconFrame.to_csv(currentDate + \"Russ Market Bacon.csv\")\n",
    "    #     self.eggFrame.to_csv(currentDate + \"Russ Market Egg.csv\")\n",
    "    #     self.tomatoFrame.to_csv(currentDate + \"Russ Market Heirloom Tomatoes.csv\")\n",
    "    #     self.log('\\n', self.baconFrame.to_string())\n",
    "    #     self.log('\\n', self.eggFrame.to_string())\n",
    "    #     self.log('\\n', self.tomatoFrame.to_string())\n",
    "    #     self.log('\\n < --- Total runtime took %s seconds with %d recoveries --- >' % (time.time() - self.runTime, self.totalRecoveries))\n",
    "    #     self.Logs_to_file(currentDate + self.name + ' Logs.txt')\n",
    "\n",
    "    #Collecting the data from the xpath in JavaScript is faster and results in fewer errors than doing it in python\n",
    "    def javascriptXpath(self, xpath):\n",
    "        try: \n",
    "            #Waits for page to load \n",
    "            ignored_exceptions=(NoSuchElementException,StaleElementReferenceException)\n",
    "            elements = WebDriverWait(self.driver, self.waitTime, ignored_exceptions=ignored_exceptions).until(EC.presence_of_all_elements_located((By.XPATH, xpath)))\n",
    "            #Runs the javascript and collects the text data from the inputed xpath\n",
    "            text = self.driver.execute_script(\"\"\"\n",
    "                const element = document.evaluate(arguments[0], document, null, XPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue;\n",
    "                if (!element) {\n",
    "                    return 'Skip';\n",
    "                }\n",
    "                return element.textContent.trim();\n",
    "            \"\"\", \n",
    "            xpath)\n",
    "            self.log('found ', text, ' for xpath: ', xpath)\n",
    "            return text\n",
    "        except TimeoutException:\n",
    "            #This means the xpath wasnt found in the page\n",
    "            self.log('Could not find xpath for: ', xpath)\n",
    "            return 'Empty'\n",
    "\n",
    "    def xpathMaker(self):\n",
    "        xpathList = [\"/html/body/div[1]/div/div[3]/div/section/article/section/div[5]/div[1]/div/div/div[1]\"]\n",
    "        #Add the xpaths here and mark if they are optional\n",
    "        # nameXpath = '//*[contains(@class, \"product-details_detailsContainer\")]/h1'\n",
    "        # priceXpath = '//*[contains(@class, \"product-details_detailsContainer\")]/p[1]'\n",
    "        # prevPriceXpath = '//*[contains(@class, \"product-details_detailsContainer\")]/p[2]'\n",
    "        # weightXpath = '//*[contains(@class, \"product-details_detailsContainer\")]/p[3]' # optional\n",
    "\n",
    "        # nameXpath = '//*[@id=\"item-details\"]/h1[contains(@class, \"name\")]'\n",
    "        # brandXpath = '//*[@id=\"item-details\"]/div[1]'\n",
    "        # priceXpath = '//*[@id=\"item-details\"]//*[contains(@class, \"wc-pricing\")]/div[1]'\n",
    "        # prevPriceXpath = '//*[@id=\"item-details\"]//*[contains(@class, \"wc-pricing\")]/div[2]/s' # optional\n",
    "        #xpath, Optional\n",
    "\n",
    "        # xpathList = [(nameXpath, False),\n",
    "        #              (priceXpath, False),\n",
    "        #              (prevPriceXpath, False),\n",
    "        #              (weightXpath, True)]\n",
    "        return xpathList\n",
    "\n",
    "    #This handles the reqests \n",
    "    def makeRequest(self, url):\n",
    "        xpathList = self.xpathMaker()\n",
    "        self.log(\"xpath list retrieved \", xpathList)\n",
    "        item = []\n",
    "        time.sleep(1) # marionette Error Fix\n",
    "        for xpath in xpathList:\n",
    "            data = 'Skip'\n",
    "            #Retrying the xpath given the number of attempts\n",
    "            for attempt in range(self.attempts):\n",
    "                data = self.javascriptXpath(xpath[0])\n",
    "                if data == 'Empty':     #Cache If the page isnt fully loaded and xpath isnt found\n",
    "                    if xpath[1]:\n",
    "                        self.debug(\"xpath wasnt avaliable\")\n",
    "                        item.append(None)\n",
    "                        break\n",
    "                    self.debug(\"Missing item retrying\")\n",
    "                elif data == 'Skip':    #Cache If the page is fully loaded with the xpath found but xpath data isnt found \n",
    "                    self.debug(\"An data has been skipped retrying\")   \n",
    "                else:                   #Data found\n",
    "                    item.append(data)\n",
    "                    self.log(data + ' was added to the list for: ', url)\n",
    "                    break\n",
    "            if data == 'Skip':  #To help clean the data we skip the item with gaps of data \n",
    "                self.debug(\"An Item has been skipped for: \", url)  \n",
    "                return ['Skipped']*len(xpathList)\n",
    "        return self.DataCleaning(item, url)\n",
    "        \n",
    "    def requestBacon( self ):\n",
    "        baconUrls = Products.Bacon.value[1]\n",
    "        total = len(baconUrls)\n",
    "        while self.count < total:\n",
    "            url = baconUrls[self.count]\n",
    "            self.driver.get(url)\n",
    "            self.log(\"Making a request for: \", url)\n",
    "            items = self.makeRequest(url) \n",
    "            self.debug('Extracted: ', items)\n",
    "            self.baconFrame.loc[len(self.baconFrame)] = items                    \n",
    "            self.count += 1\n",
    "            self.printer(\"Bacon item added \", self.count, \" of \", total, \":  \", items)\n",
    "\n",
    "    def requestEgg(self): \n",
    "        eggsUrls = Products.Eggs.value[1]\n",
    "        total = len(eggsUrls)\n",
    "        while self.count < total:\n",
    "            url = eggsUrls[self.count]\n",
    "            self.driver.get(url)\n",
    "            self.log(\"Making a request for: \", url)\n",
    "            items = self.makeRequest(url) \n",
    "            self.debug('Extracted: ', items)\n",
    "            self.eggFrame.loc[len(self.eggFrame)] = items                    \n",
    "            self.count += 1\n",
    "            self.printer(\"Egg item added \", self.count, \" of \", total, \":  \", items)\n",
    "    \n",
    "    def requestHeirloomTomatoes(self):\n",
    "        tomatoesUrls = Products.HeirloomTomatoes.value[1]\n",
    "        total = len(tomatoesUrls)\n",
    "        while self.count < total:\n",
    "            url = tomatoesUrls[self.count]\n",
    "            self.driver.get(url)\n",
    "            self.log(\"Making a request for: \", url)\n",
    "            items = self.makeRequest(url) \n",
    "            self.debug('Extracted: ', items)\n",
    "            self.tomatoFrame.loc[len(self.tomatoFrame)] = items                    \n",
    "            self.count += 1\n",
    "            self.printer(\"Heirloom tomato item added \", self.count, \" of \", total, \":  \", items)\n",
    "\n",
    "    def requestTest(self):\n",
    "        testUrls = Products.Test.value[1]\n",
    "        total = len(testUrls)\n",
    "        while self.count < total:\n",
    "            url = testUrls[self.count]\n",
    "            self.driver.get(url)\n",
    "            self.log(\"Making a request for: \", url)\n",
    "            items = self.makeRequest(url) \n",
    "            self.debug('Extracted: ', items)\n",
    "            self.testFrame.loc[len(self.testFrame)] = items                    \n",
    "            self.count += 1\n",
    "            self.printer(\"Heirloom tomato item added \", self.count, \" of \", total, \":  \", items)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #This part is a special case for this particular spider cleaning could be implemented here\n",
    "    def DataCleaning(self, item, url):\n",
    "        self.debug('Data cleaning started: ', item)\n",
    "        \n",
    "        self.debug('Data cleaning finished: ', item)\n",
    "        return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: An error occurred: Message: Malformed URL: URL constructor: url = \"https://www.russmarket.com/shop/produce/fresh_vegetables/tomatoes/heirloom_tomatoes/p/12412\" is not a valid URL.\n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:183:5\n",
      "InvalidArgumentError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:312:5\n",
      "GeckoDriver.prototype.navigateTo@chrome://remote/content/marionette/driver.sys.mjs:828:11\n",
      "\n",
      "Debug: Recovering extraction and continueing\n",
      "Logger: Driver restarted\n",
      "Debug: An error occurred: Message: Malformed URL: URL constructor: url = \"https://www.russmarket.com/shop/produce/fresh_vegetables/tomatoes/heirloom_tomatoes/p/12412\" is not a valid URL.\n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:183:5\n",
      "InvalidArgumentError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:312:5\n",
      "GeckoDriver.prototype.navigateTo@chrome://remote/content/marionette/driver.sys.mjs:828:11\n",
      "\n",
      "Debug: Recovering extraction and continueing\n",
      "Logger: Driver restarted\n",
      "Debug: An error occurred: Message: Malformed URL: URL constructor: url = \"https://www.russmarket.com/shop/produce/fresh_vegetables/tomatoes/heirloom_tomatoes/p/12412\" is not a valid URL.\n",
      "Stacktrace:\n",
      "RemoteError@chrome://remote/content/shared/RemoteError.sys.mjs:8:8\n",
      "WebDriverError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:183:5\n",
      "InvalidArgumentError@chrome://remote/content/shared/webdriver/Errors.sys.mjs:312:5\n",
      "GeckoDriver.prototype.navigateTo@chrome://remote/content/marionette/driver.sys.mjs:828:11\n",
      "\n",
      "Debug: Recovering extraction and continueing\n"
     ]
    }
   ],
   "source": [
    "# Start\n",
    "#DEBUG Switch\n",
    "SHOW = True\n",
    "spider = RussMarketSpider()\n",
    "spider.LOGGER = True\n",
    "spider.DEBUGGER = True\n",
    "spider.start_requests()\n",
    "if(SHOW):\n",
    "    print(spider.baconFrame)\n",
    "    print(spider.eggFrame)\n",
    "    print(spider.tomatoFrame)\n",
    "    spider.printLogs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSPG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
