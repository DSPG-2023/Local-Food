{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from enum import Enum\n",
    "#Imports for Scraping\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service as FirefoxService\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from os import path\n",
    "import time\n",
    "\n",
    "#This class is here so that we can expand to differnet products easier make the spider \n",
    "#more dynamic and expandable\n",
    "class Products(Enum):\n",
    "    #Name = Index, URL list\n",
    "    Bacon = 1, ['https://gatewaymarket.storebyweb.com/s/1000-1/i/INV-1000-18483',\n",
    "                'https://gatewaymarket.storebyweb.com/s/1000-1/i/INV-1000-18485',\n",
    "                'https://gatewaymarket.storebyweb.com/s/1000-1/i/INV-1000-24190',\n",
    "                'https://gatewaymarket.storebyweb.com/s/1000-1/i/INV-1000-18553',\n",
    "                'https://gatewaymarket.storebyweb.com/s/1000-1/i/INV-1000-33732',\n",
    "                'https://gatewaymarket.storebyweb.com/s/1000-1/i/INV-1000-18521',\n",
    "                'https://gatewaymarket.storebyweb.com/s/1000-1/i/INV-1000-18548',\n",
    "                'https://gatewaymarket.storebyweb.com/s/1000-1/i/INV-1000-18469',\n",
    "                'https://gatewaymarket.storebyweb.com/s/1000-1/i/INV-1000-33734',\n",
    "                'https://gatewaymarket.storebyweb.com/s/1000-1/i/INV-1000-33736',\n",
    "                'https://gatewaymarket.storebyweb.com/s/1000-1/i/INV-1000-33731',\n",
    "                'https://gatewaymarket.storebyweb.com/s/1000-1/i/INV-1000-29349',\n",
    "                'https://gatewaymarket.storebyweb.com/s/1000-1/i/INV-1000-18524',\n",
    "                'https://gatewaymarket.storebyweb.com/s/1000-1/i/INV-1000-24260',\n",
    "                'https://gatewaymarket.storebyweb.com/s/1000-1/i/INV-1000-24163',\n",
    "                'https://gatewaymarket.storebyweb.com/s/1000-1/i/INV-1000-18482'\n",
    "                ]\n",
    "    Eggs = 2, ['https://gatewaymarket.storebyweb.com/s/1000-1/i/INV-1000-22775',\n",
    "               'https://gatewaymarket.storebyweb.com/s/1000-1/i/INV-1000-22776',\n",
    "               'https://gatewaymarket.storebyweb.com/s/1000-1/i/INV-1000-12603',\n",
    "              ]\n",
    "    \n",
    "    HeirloomTomatoes = 3, ['https://gatewaymarket.storebyweb.com/s/1000-1/i/INV-1000-11820',\n",
    "                           'https://gatewaymarket.storebyweb.com/s/1000-1/i/INV-1000-22455',\n",
    "                           'https://gatewaymarket.storebyweb.com/s/1000-1/i/INV-1000-11896',\n",
    "                           'https://gatewaymarket.storebyweb.com/s/1000-1/i/INV-1000-11973',\n",
    "                           'https://gatewaymarket.storebyweb.com/s/1000-1/i/INV-1000-22343',\n",
    "                          ]\n",
    "\n",
    "class GatewaySpider():\n",
    "    name = \"Gateway Market Spider\"\n",
    "    baconFrame = pd.DataFrame(columns=['Bacon', 'Current Price', 'Original Price', 'Brand', 'Location', 'Url'])\n",
    "    eggFrame = pd.DataFrame(columns=['Egg', 'Current Price', 'Original Price', 'Brand', 'Location', 'Url'])\n",
    "    tomatoFrame = pd.DataFrame(columns=['Heirloom Tomato', 'Current Price', 'Original Price', 'Brand', 'Location', 'Url'])\n",
    "    spiderLogs = []\n",
    "    skipped = []\n",
    "\n",
    "    #These are methods that are available for your convences\n",
    "    def log(self, *args):\n",
    "        self.spiderLogs.append(('Logger:', args))\n",
    "        if self.LOGGER:\n",
    "            print('Logger:', *args)\n",
    "\n",
    "    def debug(self, *args):\n",
    "        self.spiderLogs.append(('Debug:', args))\n",
    "        if self.DEBUGGER:\n",
    "            print('Debug:', *args)\n",
    "    \n",
    "    def printer(self, *args):\n",
    "        self.spiderLogs.append(('Printer:', args))\n",
    "        print(*args)\n",
    "    \n",
    "    def printLogs(self):\n",
    "        print(\"\\n< --- Printing Logs --- >\\n\")\n",
    "        for entry in self.spiderLogs:\n",
    "            print(*entry)\n",
    "\n",
    "    def Logs_to_file(self, filename):\n",
    "        with open(filename, 'w') as file:\n",
    "            for log_entry in self.spiderLogs:\n",
    "                file.write('{} {}\\n'.format(log_entry[0], log_entry[1]))\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.DEBUGGER = False #The debugger switch to see whats going on. The Default is False\n",
    "        self.LOGGER = False #When you need to see everything that happends. The Default is False\n",
    "        self.attempts = 3 #The number of attempts the spider can retry if an error occurs. Default is 3\n",
    "        self.waitTime = 10 #The number of seconds WebDriver will wait. Default is 10\n",
    "        self.count = 0 #This saves the location of the url we are going through\n",
    "        self.runTime = 0 #Total time of extractions\n",
    "        self.totalRecoveries = 0 #Number of recoveries made while running\n",
    "        #Selenium needs a webdriver to work. I chose Firefox however you can do another if you need too\n",
    "        self.driver = webdriver.Firefox(service=FirefoxService(GeckoDriverManager().install(), log_path=path.devnull))\n",
    "        self.log(\"Driver started\")\n",
    "        \n",
    "    def restart(self):\n",
    "        self.driver.close()\n",
    "        self.driver.quit()\n",
    "        self.driver = webdriver.Firefox(service=FirefoxService(GeckoDriverManager().install(), log_path=path.devnull))\n",
    "        self.log(\"Driver restarted\")\n",
    "    \n",
    "    def forceQuit(self):\n",
    "        self.printer(\"Browser window was closed by user. Stopping program\")\n",
    "        self.log('\\n < --- Total runtime took %s seconds with %d recoveries --- >' % (time.time() - self.runTime, self.totalRecoveries))\n",
    "        self.Logs_to_file(self.name + ' Logs.txt')\n",
    "        self.driver.quit()\n",
    "\n",
    "    def requestExtraction(self, productType):\n",
    "        self.count = 0\n",
    "        errors = 0\n",
    "        extractionType = productType.value[0]\n",
    "        start = time.time()\n",
    "        for trying in range(self.attempts):\n",
    "            try:\n",
    "                if extractionType == 1:\n",
    "                    self.requestBacon()\n",
    "                elif extractionType == 2:\n",
    "                    self.requestEgg()\n",
    "                elif extractionType == 3:\n",
    "                    self.requestHeirloomTomatoes()\n",
    "                # Add elif for more products here\n",
    "                else:\n",
    "                    self.debug(\"An error extractionType for \" + str(extractionType) + \" has occured\")\n",
    "                self.debug(productType.name + \" Finished\")    \n",
    "                self.log('\\n< --- ' + productType.name + ' scrape took %s seconds with %d recoveries --- >\\n' % ((time.time() - start), errors))\n",
    "                self.totalRecoveries += errors\n",
    "                return self.totalRecoveries\n",
    "            except WebDriverException:\n",
    "                self.forceQuit()\n",
    "                return None\n",
    "            except Exception as e:\n",
    "                errors += 1\n",
    "                self.debug(\"An error occurred:\", e)\n",
    "                self.debug(\"Recovering extraction and continueing\")\n",
    "                self.restart() \n",
    "        self.debug(productType.name + \" Did not Finished after \" + str(self.attempts) + \" Time wasted: %s seconds\" % (time.time() - start))\n",
    "        self.totalRecoveries += errors\n",
    "        return self.totalRecoveries\n",
    "\n",
    "    def start_requests( self ):\n",
    "        self.runTime = time.time()\n",
    "        self.totalRecoveries = 0 \n",
    "        result = self.requestExtraction(Products.Bacon)\n",
    "        if(result == None): return\n",
    "        result = self.requestExtraction(Products.Eggs)\n",
    "        if(result == None): return\n",
    "        result = self.requestExtraction(Products.HeirloomTomatoes)\n",
    "        if(result == None): return\n",
    "        self.driver.close()\n",
    "        self.driver.quit()\n",
    "        #Adds the date that the data was scraped\n",
    "        currentDate = str(datetime(datetime.today().year, datetime.today().month, datetime.today().day))[:-8]\n",
    "        self.log(\"Exporting files\")\n",
    "        #Dataframes to CSV files\n",
    "        self.baconFrame.to_csv(currentDate + \"Gateway Market Bacon.csv\")\n",
    "        self.eggFrame.to_csv(currentDate + \"Gateway Market Egg.csv\")\n",
    "        self.tomatoFrame.to_csv(currentDate + \"Gateway Market Heirloom Tomatoes.csv\")\n",
    "        self.log('\\n', self.baconFrame.to_string())\n",
    "        self.log('\\n', self.eggFrame.to_string())\n",
    "        self.log('\\n', self.tomatoFrame.to_string())\n",
    "        self.debug('\\n < --- Total runtime took %s seconds with %d recoveries --- >' % (time.time() - self.runTime, self.totalRecoveries))\n",
    "        self.debug('\\n < --- Number of skips ' + str(len(self.skipped)) +' --->')\n",
    "        if len(self.skipped) != 0:\n",
    "            self.debug(self.skipped)\n",
    "        self.Logs_to_file(currentDate + self.name + ' Logs.txt')\n",
    "\n",
    "\n",
    "    \n",
    "    #This handles the xpaths \n",
    "    #most websites have simular xpaths for each item. You might need to make differnet xpaths for each item \n",
    "    #if that is the case\n",
    "    #For assigning xpaths mark them if they are optional meaning it could or could not be present on the page \n",
    "    #we do this for speed up if you mark it as non optional and its not pressent it will skip the value \n",
    "    #and hurt the preformence\n",
    "    #best practice is to render the optional last so it reduces the chances of skipping \n",
    "    def xpathMaker(self):\n",
    "        #Add the xpaths here and mark if they are optional\n",
    "        nameXpath = '//*[@id=\"item-details\"]/h1[contains(@class, \"name\")]'\n",
    "        priceXpath = '//*[@id=\"item-details\"]//*[contains(@class, \"wc-pricing\")]/div[1]'\n",
    "        prevPriceXpath = '//*[@id=\"item-details\"]//*[contains(@class, \"wc-pricing\")]/div[2]/s' # optional\n",
    "        brandXpath = '//*[@id=\"item-details\"]/div[1]' # optional\n",
    "        #xpath, Optional\n",
    "        xpathList = [(nameXpath, False),\n",
    "                     (priceXpath, False),\n",
    "                     (prevPriceXpath, True),\n",
    "                     (brandXpath, True)]\n",
    "        return xpathList\n",
    "    \n",
    "    #Collecting the data from the xpath in JavaScript is faster and results in fewer errors than doing it in python\n",
    "    def javascriptXpath(self, xpath):\n",
    "        try: \n",
    "            #Waits for page to load \n",
    "            ignored_exceptions=(NoSuchElementException,StaleElementReferenceException)\n",
    "            elements = WebDriverWait(self.driver, self.waitTime, ignored_exceptions=ignored_exceptions).until(EC.presence_of_all_elements_located((By.XPATH, xpath)))\n",
    "            for quickRetry in range(self.attempts): #this is for fast computers\n",
    "                #Runs the javascript and collects the text data from the inputed xpath\n",
    "                text = self.driver.execute_script(\"\"\"\n",
    "                    const element = document.evaluate(arguments[0], document, null, XPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue;\n",
    "                    if (!element) {\n",
    "                        return 'Skip';\n",
    "                    }\n",
    "                    return element.textContent.trim();\n",
    "                \"\"\", \n",
    "                xpath)\n",
    "                if self.checkOutput(text):\n",
    "                    time.sleep(1)\n",
    "                else:\n",
    "                    self.log('found ', text, ' for xpath: ', xpath)\n",
    "                    return text\n",
    "        except TimeoutException:\n",
    "            #This means the xpath wasnt found in the page\n",
    "            self.log('Could not find xpath for: ', xpath)\n",
    "        return 'Empty'\n",
    "\n",
    "    def checkOutput(self, check):\n",
    "        self.log('Validing input')\n",
    "        invalidOutputs = {\"error\", 'skip', \"$nan\", ''}\n",
    "        if check.lower() in invalidOutputs:\n",
    "            self.log(\"Invalid word:\", check)\n",
    "            return True\n",
    "        else:\n",
    "            self.log(\"Valid\")\n",
    "            return False\n",
    "\n",
    "    #This handles the reqests \n",
    "    def makeRequest(self, url):\n",
    "        xpathList = self.xpathMaker()\n",
    "        self.log(\"xpath list retrieved \", xpathList)\n",
    "        item = []\n",
    "        time.sleep(1) # marionette Error Fix\n",
    "        for xpath in xpathList:\n",
    "            data = 'skip'\n",
    "            #Retrying the xpath given the number of attempts\n",
    "            for attempt in range(self.attempts):\n",
    "                data = self.javascriptXpath(xpath[0])\n",
    "                if(self.checkOutput(data)): # Data not found\n",
    "                    self.debug(\"Missing item retrying\")\n",
    "                elif data == 'Empty':     \n",
    "                    if xpath[1]:\n",
    "                        self.debug(\"xpath wasnt avaliable\")\n",
    "                        item.append(None)\n",
    "                        break\n",
    "                    self.debug(\"Missing item retrying\")\n",
    "                else:  #Data found\n",
    "                    item.append(data)\n",
    "                    self.log(data + ' was added to the list for: ', url)\n",
    "                    break\n",
    "            if data == 'skip':  #To help clean the data we skip the item with gaps of data \n",
    "                self.debug(\"An Item has been skipped for: \", url)  \n",
    "                item = ['Skipped']*(len(xpathList))\n",
    "                self.skipped.append(url)\n",
    "        return self.DataCleaning(item, url)\n",
    "    \n",
    "    def requestBacon( self ):\n",
    "        baconUrls = Products.Bacon.value[1]\n",
    "        total = len(baconUrls)\n",
    "        while self.count < total:\n",
    "            url = baconUrls[self.count]\n",
    "            self.driver.get(url)\n",
    "            self.log(\"Making a request for: \", url)\n",
    "            items = self.makeRequest(url) \n",
    "            self.debug('Extracted: ', items)\n",
    "            self.baconFrame.loc[len(self.baconFrame)] = items                    \n",
    "            self.count += 1\n",
    "            self.printer(\"Bacon item added \", self.count, \" of \", total, \":  \", items)\n",
    "\n",
    "    def requestEgg(self): \n",
    "        eggsUrls = Products.Eggs.value[1]\n",
    "        total = len(eggsUrls)\n",
    "        while self.count < total:\n",
    "            url = eggsUrls[self.count]\n",
    "            self.driver.get(url)\n",
    "            self.log(\"Making a request for: \", url)\n",
    "            items = self.makeRequest(url) \n",
    "            self.debug('Extracted: ', items)\n",
    "            self.eggFrame.loc[len(self.eggFrame)] = items                    \n",
    "            self.count += 1\n",
    "            self.printer(\"Egg item added \", self.count, \" of \", total, \":  \", items)\n",
    "    \n",
    "    def requestHeirloomTomatoes(self):\n",
    "        tomatoesUrls = Products.HeirloomTomatoes.value[1]\n",
    "        total = len(tomatoesUrls)\n",
    "        while self.count < total:\n",
    "            url = tomatoesUrls[self.count]\n",
    "            self.driver.get(url)\n",
    "            self.log(\"Making a request for: \", url)\n",
    "            items = self.makeRequest(url) \n",
    "            self.debug('Extracted: ', items)\n",
    "            self.tomatoFrame.loc[len(self.tomatoFrame)] = items                    \n",
    "            self.count += 1\n",
    "            self.printer(\"Heirloom tomato item added \", self.count, \" of \", total, \":  \", items)\n",
    "\n",
    "    #This part is a special case for this particular spider cleaning could be implemented here\n",
    "    def DataCleaning(self, item, url):\n",
    "        self.debug('Data cleaning started: ', item)\n",
    "        item.append(\"2002 Woodland Avenue Des Moines, IA 50312\")\n",
    "        item.append(url)\n",
    "        self.debug('Data cleaning finished: ', item)\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start\n",
    "#DEBUG Switch\n",
    "SHOW = True\n",
    "spider = GatewaySpider()\n",
    "# spider.LOGGER = True\n",
    "spider.DEBUGGER = True\n",
    "spider.start_requests()\n",
    "if(SHOW):\n",
    "    print(spider.baconFrame)\n",
    "    print(spider.eggFrame)\n",
    "    print(spider.tomatoFrame)\n",
    "    spider.printLogs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSPG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
