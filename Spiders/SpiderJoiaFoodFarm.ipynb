{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.utils.log import configure_logging\n",
    "from DSPG_Products import Products #Imports the products to be processed\n",
    "from DSPG_Cleaner import DataCleaner # This is to handle the cleaning of data\n",
    "from DSPG_SpiderErrors import DataFormatingError\n",
    "\n",
    "class JoiaFoodFarmSpider(scrapy.Spider):\n",
    "    name = 'Joia Food Farm'\n",
    "    currentDate = str(datetime(datetime.today().year, datetime.today().month, datetime.today().day))[:-8]\n",
    "    def start_requests( self ):\n",
    "        #Bacon Scraper part\n",
    "         \n",
    "        JoiaFoodFarmBaconUrls = 'https://www.joiafoodfarm.com/farmstore?category=Pork'\n",
    "        yield scrapy.Request( url = JoiaFoodFarmBaconUrls, callback = self.JoiaFoodFarmSearch, meta={'type': 'bacon'})\n",
    "        \n",
    "        JoiaFoodFarmEggsUrls = 'https://www.joiafoodfarm.com/farmstore?category=Eggs'\n",
    "        yield scrapy.Request( url = JoiaFoodFarmEggsUrls, callback = self.JoiaFoodFarmSearch, meta={'type': 'eggs'})\n",
    "\n",
    "    def JoiaFoodFarmSearch(self, response):\n",
    "        #Failsafe for links\n",
    "        try:\n",
    "            #grabs all cards from list and saves the link to follow\n",
    "            xpath = '//main//*[contains(@class, \"ProductList-grid\")]//*[contains(@class, \"ProductList-item-link\")]/@href'\n",
    "            linkList = response.xpath(xpath)\n",
    "            productType = response.meta.get('type')\n",
    "            if productType == 'bacon':\n",
    "                for url in linkList:\n",
    "                    yield response.follow( url = url, callback = self.JoiaFoodFarmBacon, dont_filter=True )\n",
    "            elif productType == 'eggs':\n",
    "                for url in linkList:\n",
    "                    yield response.follow( url = url, callback = self.JoiaFoodFarmEggs, dont_filter=True )\n",
    "        except AttributeError:\n",
    "           pass\n",
    "\n",
    "    def JoiaFoodFarmBacon(self, response):\n",
    "        nameXpath = '//*[contains(@class, \"ProductItem-summary\")]//h1[contains(@class, \"ProductItem-details-title\")]/text()'\n",
    "        name = response.xpath(nameXpath).extract_first()\n",
    "        if \"bacon\" not in name.lower():\n",
    "            return          \n",
    "        \n",
    "        #load cleaner template\n",
    "        clean = DataCleaner()\n",
    "        clean.LoadDataSet(0, response.url)\n",
    "        clean.Data['Product Type'] = name\n",
    "        \n",
    "        #The other areas we are interested in\n",
    "        priceXpath = '//*[contains(@class, \"ProductItem-summary\")]//*[contains(@class, \"product-price\")]/text()'    \n",
    "        clean.Data['Current Price'] = response.xpath(priceXpath).extract_first()\n",
    "        \n",
    "        #getting the product discription\n",
    "        discXpath = '//*[contains(@class, \"ProductItem-summary\")]//*[contains(@class, \"ProductItem-details-excerpt\")]/descendant-or-self::text()'\n",
    "        description = response.xpath(discXpath).getall()\n",
    "        # remove leading and trailing whitespace from each string\n",
    "        description = [text.strip() for text in description]\n",
    "        # remove empty strings\n",
    "        description = list(filter(None, description))\n",
    "        # join the strings into a single string\n",
    "        descriptionText = \" \".join(description)\n",
    "        unit = clean.findWeightUnit(descriptionText)\n",
    "        if not unit:\n",
    "            unit = clean.findWeightUnit(clean.Data['Product Type'])\n",
    "        clean.Data['True Weight'] = unit\n",
    "        clean.Data['Weight in lbs'] = clean.ozToLb(clean.Data['True Weight'])\n",
    "        clean.cleanPricing()\n",
    "        clean = self.setLocationalData(clean)\n",
    "        JoiaFoodFarmBaconDataFrame.loc[len(JoiaFoodFarmBaconDataFrame)] = list(clean.Data.values())\n",
    "\n",
    "    def JoiaFoodFarmEggs(self, response):\n",
    "        nameXpath = '//*[contains(@class, \"ProductItem-summary\")]//h1[contains(@class, \"ProductItem-details-title\")]/text()'\n",
    "        name = response.xpath(nameXpath).extract_first()\n",
    "        if \"egg\" not in name.lower():\n",
    "            return \n",
    "        \n",
    "        #load cleaner template\n",
    "        clean = DataCleaner()\n",
    "        clean.LoadDataSet(1, response.url)\n",
    "        clean.Data['Product Type'] = name\n",
    "        \n",
    "        #The other areas we are interested in       \n",
    "        priceXpath = '//*[contains(@class, \"ProductItem-summary\")]//*[contains(@class, \"product-price\")]/text()'\n",
    "        clean.Data['Current Price'] = response.xpath(priceXpath).extract_first()\n",
    "        \n",
    "        #getting the product discription\n",
    "        discXpath = '//*[contains(@class, \"ProductItem-summary\")]//*[contains(@class, \"ProductItem-details-excerpt\")]/descendant-or-self::text()'\n",
    "        description = response.xpath(discXpath).getall()\n",
    "        # remove leading and trailing whitespace from each string\n",
    "        description = [text.strip() for text in description]\n",
    "        # remove empty strings\n",
    "        description = list(filter(None, description))\n",
    "        # join the strings into a single string\n",
    "        descriptionText = \" \".join(description)\n",
    "        if not clean.EggFinder(descriptionText):\n",
    "            clean.EggFinder(clean.Data['Product Type'])\n",
    "        clean.determineLocality()\n",
    "        clean.cleanPricing()\n",
    "        clean = self.setLocationalData(clean)\n",
    "        #Adding product to data frame\n",
    "        JoiaFoodFarmEggsDataFrame.loc[len(JoiaFoodFarmEggsDataFrame)] = list(clean.Data.values())\n",
    "\n",
    "    def setLocationalData(self, clean):\n",
    "        clean.Data['Address'] = '2038 March Avenue'\n",
    "        clean.Data['State'] = 'IA'\n",
    "        clean.Data['City'] = 'Charles City'\n",
    "        clean.Data['Zip Code'] = '50616'    \n",
    "        return clean \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "#Data frames\n",
    "JoiaFoodFarmBaconDataFrame = pd.DataFrame(columns=['Bacon', 'Current Price', 'Orignal Price', 'Weight in lbs', 'True Weight', 'Brand', 'Local', 'Address', 'State', 'City', 'Zip Code', 'Date Collected', 'Url']) #Bacon Frame\n",
    "JoiaFoodFarmEggsDataFrame = pd.DataFrame(columns=['Egg', 'Current Price', 'Orignal Price', 'Amount in dz', 'True Amount', 'Brand', 'Local', 'Address', 'State', 'City', 'Zip Code', 'Date Collected', 'Url']) #Egg Frame\n",
    "\n",
    "currentDate = str(datetime(datetime.today().year, datetime.today().month, datetime.today().day))[:-8]\n",
    "\n",
    "if(DEBUG):\n",
    "    #To see the inner mechanics of the spider\n",
    "    configure_logging()\n",
    "\n",
    "#This is to start the spider\n",
    "process = CrawlerProcess()\n",
    "process.crawl(JoiaFoodFarmSpider)\n",
    "process.start()\n",
    "process.stop()\n",
    "currentDate = str(datetime(datetime.today().year, datetime.today().month, datetime.today().day))[:-8]\n",
    "\n",
    "if(DEBUG):\n",
    "    #To see the inner mechanics of the spider\n",
    "    configure_logging()\n",
    "\n",
    "JoiaFoodFarmBaconDataFrame.to_csv(currentDate + \"Joia Food Farm Bacon.csv\", index=False)\n",
    "JoiaFoodFarmEggsDataFrame.to_csv(currentDate + \"Joia Food Farm Eggs.csv\", index=False)\n",
    "\n",
    "if(DEBUG):\n",
    "    #To see the outputs\n",
    "    print(JoiaFoodFarmBaconDataFrame)\n",
    "    print(JoiaFoodFarmEggsDataFrame)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSPG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
