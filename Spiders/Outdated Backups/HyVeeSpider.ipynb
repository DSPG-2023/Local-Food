{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from enum import Enum\n",
    "#Imports for Scraping\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service as FirefoxService\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from os import path\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "#Creator's Note: Products(Enum) and ProductsLoader is probably the only classes you need to edit \n",
    "#unless you need to change the way the data is cleaned. Which handled in the DataCleaner class\n",
    "\n",
    "#These class is here so that we can expand to differnet products easier making the spider more dynamic and expandable\n",
    "class Products(Enum):\n",
    "    #Add products like this ProductName = index iteration, [], [] \n",
    "    #the 2 empty list will be filled in using the ProductsLoader class\n",
    "    Bacon = 0, [], []\n",
    "    Eggs = 1, [], []\n",
    "    HeirloomTomatoes = 2, [], []\n",
    "\n",
    "    # Helper method to reduce code for adding to the products and weed out duplicate inputs\n",
    "    # if you type something in really wrong code will stop the setup is important \n",
    "    # correct index inputs are correct index number, url, urls, xpath, xpaths\n",
    "    def addToProduct(self, items, index):\n",
    "        product = None\n",
    "        if isinstance(index, int):\n",
    "            product = self.value[index]\n",
    "        elif isinstance(index, str):\n",
    "            if index.lower() in ['urls', 'url']:\n",
    "                product = self.value[1]\n",
    "            elif index.lower() in ['xpaths', 'xpath']:\n",
    "                product = self.value[2]\n",
    "        if product == None:\n",
    "            raise ValueError(f\"Invalid index input for ({index}) for input: {items}\")\n",
    "        #Sets are fast at finding dups so we use them for speed\n",
    "        product_set = set(product)\n",
    "        for item in items:\n",
    "            if item not in product_set:\n",
    "                product.append(item)\n",
    "                product_set.add(item)\n",
    "\n",
    "#This class loads the xpaths and urls to the Products Enum and adds dataframes to the spider\n",
    "class ProductsLoader():\n",
    "    DataFrames = []\n",
    "    def __init__(self):\n",
    "        self.dataFrameAdder()\n",
    "        self.urlsAdder()\n",
    "        self.xpathMaker()\n",
    "\n",
    "    #This adds the dataframe to the spider on load\n",
    "    def dataFrameAdder(self):\n",
    "        #Dataframes (You can add more here)\n",
    "        baconFrame = pd.DataFrame(columns=['Bacon', 'Current Price', 'Sale', 'Weight', 'Url'])\n",
    "        eggFrame = pd.DataFrame(columns=['Egg', 'Current Price', 'Sale', 'Amount', 'Url'])\n",
    "        tomatoFrame = pd.DataFrame(columns=['Heirloom Tomato', 'Current Price', 'Sale', 'Weight', 'Url'])\n",
    "        self.DataFrames = [baconFrame,\n",
    "                           eggFrame,\n",
    "                           tomatoFrame\n",
    "                          ]\n",
    "\n",
    "    #Adding Urls to products\n",
    "    def urlsAdder(self):\n",
    "        BaconUrls = ['https://www.hy-vee.com/aisles-online/p/11315/Hormel-Black-Label-Thick-Cut-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/47128/Hormel-Black-Label-Fully-Cooked-Original-Thick-Cut-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/41626/Applegate-Naturals-Uncured-Sunday-Bacon-Hickory-Smoked',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/57278/HyVee-Double-Smoked-Thick-Sliced-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/2405550/Applegate-Naturals-No-Sugar-Uncured-Bacon-Hickory-Smoked',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/57279/HyVee-Sweet-Smoked-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/11366/Hormel-Black-Label-Original-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/2455081/Jimmy-Dean-Premium-Hickory-Smoked-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/3595492/Farmland-Bacon-Double-Smoked-Double-Thick-Cut',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/47117/Hormel-Black-Label-Center-Cut-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/57277/HyVee-Center-Cut-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/2199424/Country-Smokehouse-Thick-Applewood-Slab-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/77228/Hormel-Black-Label-Original-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/21239/Farmland-Naturally-Hickory-Smoked-Classic-Cut-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/2456254/Jimmy-Dean-Premium-Applewood-Smoked-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/21240/Farmland-Naturally-Hickory-Smoked-Thick-Cut-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/47159/Hormel-Black-Label-Original-Bacon-4Pk',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/50315/Oscar-Mayer-Naturally-Hardwood-Smoked-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/50321/Oscar-Mayer-Center-Cut-Original-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/50316/Oscar-Mayer-Thick-Cut-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/2199421/Country-Smokehouse-Thick-Hickory-Smoked-Slab-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/104466/Hickory-Country-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/23975/HyVee-Hickory-House-Applewood-Naturally-Smoked-Thick-Sliced-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/23949/HyVee-Sweet-Smoked-Thick-Sliced-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/23963/HyVee-Fully-Cooked-Hickory-Smoked-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/11173/Hormel-Black-Label-Applewood-Thick-Cut-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/21317/Farmland-Naturally-Applewood-Smoked-Classic-Cut-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/21238/Farmland-Naturally-Hickory-Smoked-Thick-Cut-Bacon-Package',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/23948/HyVee-Lower-Sodium-Sweet-Smoked-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/458259/Wright-Naturally-Hickory-Smoked-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/11384/Hormel-Natural-Choice-Uncured-Original-Bacon-12-oz',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/2476490/Jimmy-Dean-FC-Hickory-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/1646677/Smithfield-Hometown-Original-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/53849/Farmland-Naturally-Hickory-Smoked-Lower-Sodium-Classic-Cut-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/47121/Hormel-Black-Label-Maple-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/164627/Oscar-Mayer-Fully-Cooked-Original-Bacon-252-oz-Box',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/23974/HyVee-Hickory-House-Hickory-Smoked-Thick-Sliced-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/50319/Oscar-Mayer-Selects-Smoked-Uncured-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/2471760/Jimmy-Dean-FC-Applewood-Smoked-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/16239/Oscar-Mayer-Center-Cut-Thick-Sliced-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/2214511/Hormel-Black-Label-Original-Thick-Cut-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/1008152/Wright-Naturally-Smoked-Applewood-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/1813260/Smithfield-Naturally-Hickory-Smoked-Thick-Cut-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/23976/HyVee-Hickory-House-Peppered-Naturally-Smoked-Thick-Sliced-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/21320/Farmland-Naturally-Applewood-Smoked-Thick-Cut-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/21253/Farmland-Naturally-Hickory-Smoked-Extra-Thick-Cut-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/1255920/Hormel-Black-Label-Cherrywood-Thick-Cut-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/57304/HyVee-Blue-Ribbon-Maple-Naturally-Smoked-Thick-Sliced-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/21252/Farmland-Naturally-Hickory-Smoked-30-Less-Fat-Center-Cut-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/2501872/Bourbon-And-Brown-Sugar-Slab-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/2516586/Hormel-Natural-ChoiceOriginal-Thick-Cut-Uncured-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/21319/Farmland-Naturally-Hickory-Smoked-Double-Smoked-Classic-Cut-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/317829/Des-Moines-Bacon-And-Meat-Company-Hardwood-Smoked-Uncured-Country-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/1255919/Hormel-Black-Label-Jalapeno-Thick-Cut-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/3538865/Oscar-Mayer-Bacon-Thick-Cut-Applewood',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/317830/Des-Moines-Bacon-And-Meat-Company-Applewood-Smoked-Bacon',\n",
    "                     'https://www.hy-vee.com/aisles-online/p/3308731/Oscar-Mayer-Natural-Fully-Cooked-Uncured-Bacon'\n",
    "                    ]\n",
    "        EggUrls = ['https://www.hy-vee.com/aisles-online/p/57236/HyVee-Grade-A-Large-Eggs',\n",
    "                   'https://www.hy-vee.com/aisles-online/p/23899/HyVee-Grade-A-Large-Eggs',\n",
    "                   'https://www.hy-vee.com/aisles-online/p/715446/Farmers-Hen-House-Free-Range-Organic-Large-Brown-Grade-A-Eggs',\n",
    "                   'https://www.hy-vee.com/aisles-online/p/2849570/Thats-Smart-Large-Shell-Eggs',\n",
    "                   'https://www.hy-vee.com/aisles-online/p/31351/Farmers-Hen-House-Free-Range-Grade-A-Large-Brown-Eggs',\n",
    "                   'https://www.hy-vee.com/aisles-online/p/23900/HyVee-Grade-A-Extra-Large-Eggs',\n",
    "                   'https://www.hy-vee.com/aisles-online/p/71297/Egglands-Best-Farm-Fresh-Grade-A-Large-Eggs',\n",
    "                   'https://www.hy-vee.com/aisles-online/p/36345/Egglands-Best-Grade-A-Large-Eggs',\n",
    "                   'https://www.hy-vee.com/aisles-online/p/3192325/HyVee-Free-Range-Large-Brown-Egg-Grade-A',\n",
    "                   'https://www.hy-vee.com/aisles-online/p/23903/HyVee-Grade-A-Jumbo-Eggs',\n",
    "                   'https://www.hy-vee.com/aisles-online/p/3192323/HyVee-Cage-Free-Large-Brown-Egg-Grade-A',\n",
    "                   'https://www.hy-vee.com/aisles-online/p/36346/Egglands-Best-Cage-Free-Brown-Grade-A-Large-Eggs',\n",
    "                   'https://www.hy-vee.com/aisles-online/p/3192322/HyVee-Cage-Free-Large-Brown-Egg-Grade-A',\n",
    "                   'https://www.hy-vee.com/aisles-online/p/858343/HyVee-Cage-Free-Omega3-Grade-A-Large-Brown-Eggs',\n",
    "                   'https://www.hy-vee.com/aisles-online/p/1901565/Farmers-Hen-House-Pasture-Raised-Organic-Grade-A-Large-Brown-Eggs',\n",
    "                   'https://www.hy-vee.com/aisles-online/p/60364/HyVee-HealthMarket-Organic-Grade-A-Large-Eggs',\n",
    "                   'https://www.hy-vee.com/aisles-online/p/71298/Egglands-Best-Extra-Large-Eggs',\n",
    "                   'https://www.hy-vee.com/aisles-online/p/23902/HyVee-Grade-A-Extra-Large-Eggs',\n",
    "                   'https://www.hy-vee.com/aisles-online/p/453006/Egglands-Best-XL-Eggs',\n",
    "                   'https://www.hy-vee.com/aisles-online/p/2668550/HyVee-One-Step-Pasture-Raised-Large-Brown-Eggs',\n",
    "                   'https://www.hy-vee.com/aisles-online/p/66622/Farmers-Hen-House-Jumbo-Brown-Eggs',\n",
    "                   'https://www.hy-vee.com/aisles-online/p/3274825/Nellies-Eggs-Brown-Free-Range-Large',\n",
    "                   'https://www.hy-vee.com/aisles-online/p/57235/HyVee-Grade-A-Medium-Eggs',\n",
    "                   'https://www.hy-vee.com/aisles-online/p/2437128/Pete-And-Gerrys-Eggs-Organic-Brown-Free-Range-Large',\n",
    "                   'https://www.hy-vee.com/aisles-online/p/36347/Egglands-Best-Organic-Cage-Free-Grade-A-Large-Brown-Eggs',\n",
    "                   'https://www.hy-vee.com/aisles-online/p/2698224/Nellies-Free-Range-Eggs-Large-Fresh-Brown-Grade-A',\n",
    "                   'https://www.hy-vee.com/aisles-online/p/57237/HyVee-Grade-A-Large-Eggs',\n",
    "                   'https://www.hy-vee.com/aisles-online/p/190508/Farmers-Hen-House-Organic-Large-Brown-Eggs'\n",
    "                  ]\n",
    "        HeirloomTomatoesUrls = ['https://www.hy-vee.com/aisles-online/p/37174/']\n",
    "\n",
    "        Products.Bacon.addToProduct(BaconUrls,'urls')\n",
    "        Products.Eggs.addToProduct(EggUrls,'urls')\n",
    "        Products.HeirloomTomatoes.addToProduct(HeirloomTomatoesUrls,'urls')\n",
    "\n",
    "    #This handles the xpaths by adding to the Products class\n",
    "    #most websites have simular xpaths for each item. You might need to make differnet xpaths for each item \n",
    "    #if that is the case\n",
    "    #For assigning xpaths mark them if they are optional meaning it could or could not be present on the page \n",
    "    #we do this for speed up if you mark it as non optional and its not pressent it will skip the value \n",
    "    #and hurt the preformence\n",
    "    #best practice is to render the optional last so it reduces the chances of skipping \n",
    "    #Note spiecal cases do happen but they are extremely rare a good indiaction of finding one \n",
    "    #is by using skipHandler method and tracking/watching the logs  \n",
    "    #IMPORTANT < -!- NOT ALL XPATHS ARE THE SAME FOR EACH PRODUCT -!->\n",
    "    def xpathMaker(self):\n",
    "        #Add the xpaths here and mark if they are optional\n",
    "        nameXpath = '//*[contains(@class, \"product-details_detailsContainer\")]/h1'\n",
    "        priceXpath = '//*[contains(@class, \"product-details_detailsContainer\")]/p[1]'\n",
    "        prevPriceXpath = '//*[contains(@class, \"product-details_detailsContainer\")]/p[2]'\n",
    "        weightXpath = '//*[contains(@class, \"product-details_detailsContainer\")]/p[3]' # optional\n",
    "\n",
    "        #xpath, Optional\n",
    "        xpathList = [(nameXpath, False),\n",
    "                     (priceXpath, False),\n",
    "                     (prevPriceXpath, False),\n",
    "                     (weightXpath, True)]\n",
    "\n",
    "        Products.Bacon.addToProduct(xpathList,'xpath')\n",
    "        Products.Eggs.addToProduct(xpathList,'xpath')\n",
    "        Products.HeirloomTomatoes.addToProduct(xpathList,'xpath')\n",
    "\n",
    "class DataCleaner():\n",
    "    Data = {}\n",
    "    def cleanUp(self, input, inputType, url):\n",
    "        self.productType = inputType\n",
    "        #Define the input as a class global so the array can be used through out the class\n",
    "        if(self.productType == Products.Bacon.name):\n",
    "            self.Data = {'Product Type': input[0],\n",
    "                         'Current Price': input[1],\n",
    "                         'Orignal Price': input[3],\n",
    "                         'Weight in lbs': None,\n",
    "                         'True Weight': input[2],\n",
    "                         'Brand': None,\n",
    "                         'Local': None,\n",
    "                         'Address': None,\n",
    "                         'State': None, \n",
    "                         'City': None, \n",
    "                         'Zip Code': None, \n",
    "                         'Date Collected': str(datetime(datetime.today().year, datetime.today().month, datetime.today().day))[:-9], \n",
    "                         'Url': url\n",
    "                        }\n",
    "            if(self.Data['True Weight'] == None):\n",
    "                self.Data['True Weight'] = self.findWeight()\n",
    "            if(self.Data['True Weight'] != None):\n",
    "                self.Data['Weight in lbs'] = self.ozToLb(self.Data['True Weight'])\n",
    "        elif(self.productType == Products.Eggs.name):\n",
    "            self.Data = {'Product Type': input[0],\n",
    "                         'Current Price': input[1],\n",
    "                         'Orignal Price': input[2],\n",
    "                         'Amount in dz': None,\n",
    "                         'True Amount': input[4],\n",
    "                         'Brand': input[3],\n",
    "                         'Local': None,\n",
    "                         'Address': None,\n",
    "                         'State': None, \n",
    "                         'City': None, \n",
    "                         'Zip Code': None, \n",
    "                         'Date Collected': str(datetime(datetime.today().year, datetime.today().month, datetime.today().day))[:-9], \n",
    "                         'Url': url\n",
    "                        }\n",
    "            self.eggConverter()\n",
    "\n",
    "        elif(self.productType == Products.HeirloomTomatoes.name):\n",
    "            self.Data = {'Product Type': input[0],\n",
    "                         'Current Price': input[1],\n",
    "                         'Orignal Price': input[2],\n",
    "                         'Weight in lbs': None,\n",
    "                         'True Weight': None,\n",
    "                         'Brand': input[3],\n",
    "                         'Organic': None,\n",
    "                         'Local': None,\n",
    "                         'Address': None,\n",
    "                         'State': None, \n",
    "                         'City': None, \n",
    "                         'Zip Code': None, \n",
    "                         'Date Collected': str(datetime(datetime.today().year, datetime.today().month, datetime.today().day))[:-9], \n",
    "                         'Url': url\n",
    "                        }\n",
    "            self.tomatoModification(input[4], input[5])\n",
    "        else:\n",
    "            return None\n",
    "        self.setLocationalData()\n",
    "        self.determineLocality()\n",
    "        self.cleanPricing()\n",
    "        return list(self.Data.values())\n",
    "    \n",
    "    #Helper to reduce code. Splits the string and returns the float value \n",
    "    def stringValueExtraction(self, string, stringType):\n",
    "        value = ''.join(filter(lambda x: x.isdigit() or x == '.', string.split(stringType)[0]))\n",
    "        if(len(value) == 0):\n",
    "            return None\n",
    "        return float(value)\n",
    "    \n",
    "    def cleanPricing(self):\n",
    "        price = ''.join(c for c in self.Data['Current Price'] if c.isdigit() or c == '.')\n",
    "        if len(price) == 0:\n",
    "            return\n",
    "        self.Data['Current Price'] = float(price)\n",
    "        if self.Data['Orignal Price'] == None:\n",
    "            self.Data['Orignal Price'] = self.Data['Current Price']\n",
    "            return\n",
    "        price = ''.join(c for c in self.Data['Orignal Price'] if c.isdigit() or c == '.')\n",
    "        if len(price) == 0:\n",
    "            self.Data['Orignal Price'] = self.Data['Current Price']\n",
    "        else:\n",
    "            self.Data['Orignal Price'] = float(price)\n",
    "        \n",
    "    def ozToLb(self, input):\n",
    "        weight = str(input).lower()\n",
    "        if 'oz' in weight:\n",
    "            return self.stringValueExtraction(weight, 'oz') / 16.0\n",
    "        elif '/lb' in weight:\n",
    "            value = self.stringValueExtraction(weight, '/lb')\n",
    "            if value == None:\n",
    "                return 1.0\n",
    "            return value\n",
    "        elif 'lb' in weight:\n",
    "            return self.stringValueExtraction(weight, 'lb')\n",
    "        return weight\n",
    "\n",
    "    #Tomatoes are tricky so we have a function that does this part\n",
    "    def tomatoModification(self, byWeight, size):\n",
    "        #We can extract Organic from the name\n",
    "        if self.Data['Organic'] == None:\n",
    "            if 'organic' in self.Data['Product Type'].lower().replace(' ', ''): # convert to lowercase and remove spaces\n",
    "                self.Data['Organic'] = 'Organic'\n",
    "        #This part is for Weight\n",
    "        if size != None:\n",
    "            self.Data['True Weight'] = size\n",
    "        elif byWeight != None:\n",
    "            self.Data['True Weight'] = byWeight\n",
    "        elif self.Data['True Weight'] == None:\n",
    "            #Checking these places for clues\n",
    "            checkLocations = [self.Data['Current Price'],\n",
    "                              self.Data['Product Type'],\n",
    "                              self.Data['Orignal Price']]\n",
    "            for string in checkLocations:\n",
    "                if '/ea' in string:\n",
    "                    self.Data['True Weight'] = f\"{self.stringValueExtraction(string, '/ea')}/ea\"\n",
    "                    break\n",
    "                elif '/lb' in string:\n",
    "                    weight = self.stringValueExtraction(string, '/lb')\n",
    "                    self.Data['True Weight'] = f\"{weight}/lb\"\n",
    "                    self.Data['Weight in lbs'] = 1.0\n",
    "                    return\n",
    "            return\n",
    "        if '/lb' in self.Data['True Weight']:\n",
    "            self.Data['Weight in lbs'] = 1.0\n",
    "        \n",
    "    #If no weight is given we look at other places that could have what we need\n",
    "    #This Determines if a list talking about weights in ounces or pounds.\n",
    "    def findWeight(self):\n",
    "        #Checking these places for clues\n",
    "        checkLocations = [self.Data['Current Price'], self.Data['Product Type'], self.Data['Orignal Price']]\n",
    "        for string in checkLocations:\n",
    "            if string == None:\n",
    "                continue\n",
    "            string = string.lower().replace(' ', '') # convert to lowercase and remove spaces\n",
    "            if 'pound' in string:\n",
    "                return  f\"{self.stringValueExtraction(string, 'pound')} lb\"\n",
    "            elif 'ounce' in string:\n",
    "                return f\"{self.stringValueExtraction(string, 'ounce')} oz\"\n",
    "            elif '/lb' in string:\n",
    "                return f\"{1.0} lb\"\n",
    "            elif 'lb' in string:\n",
    "                return f\"{self.stringValueExtraction(string, 'lb')} lb\"\n",
    "            elif 'oz' in string:\n",
    "                return f\"{self.stringValueExtraction(string, 'oz')} oz\"\n",
    "        return None\n",
    "\n",
    "    #Eggs don't have weight so we use amount\n",
    "    def eggConverter(self):\n",
    "        if self.Data['True Amount'] == None:\n",
    "            checkLocations = [self.Data['Product Type'],self.Data['Current Price'],self.Data['Orignal Price']]\n",
    "            for string in checkLocations:\n",
    "                string = string.lower().replace(' ', '') # convert to lowercase and remove spaces\n",
    "                if 'dozen' in string:\n",
    "                    amount = self.stringValueExtraction(string, 'dozen')\n",
    "                    if amount == None:\n",
    "                        self.Data['True Amount'] = f\"{1} dz\"\n",
    "                        self.Data['Amount in dz'] = 1.0\n",
    "                        return\n",
    "                    self.Data['True Amount'] = f\"{amount} dz\"  \n",
    "                    self.Data['Amount in dz'] = amount\n",
    "                    return  \n",
    "                if 'dz' in string:\n",
    "                    amount = self.stringValueExtraction(string, 'dz')\n",
    "                    self.Data['True Amount'] = f\"{amount} dz\"\n",
    "                    self.Data['Amount in dz'] = amount\n",
    "                    return \n",
    "                if 'ct' in string:\n",
    "                    amount = self.stringValueExtraction(string, 'ct')\n",
    "                    self.Data['True Amount'] = f\"{amount} ct\"  \n",
    "                    self.Data['Amount in dz'] = amount / 12\n",
    "                    return\n",
    "        else:\n",
    "            string = self.Data['True Amount'].lower().replace(' ', '')\n",
    "            if 'dozen' in string:\n",
    "                amount = self.stringValueExtraction(string, 'dozen')\n",
    "                if amount == None:\n",
    "                    self.Data['Amount in dz'] = 1.0\n",
    "                    return\n",
    "                self.Data['Amount in dz'] = amount\n",
    "            if 'dz' in string:\n",
    "                self.Data['Amount in dz'] = self.stringValueExtraction(string, 'dz')\n",
    "            if 'ct' in string:\n",
    "                self.Data['Amount in dz'] = self.stringValueExtraction(string, 'ct') / 12\n",
    "\n",
    "    def determineLocality(self):\n",
    "        localBrands = None\n",
    "        nonlocalBrands = None\n",
    "        #For speed we use sets and turn everyting to lowercase and no spaces for accuracy\n",
    "        if(self.productType == Products.Bacon.name): \n",
    "            localBrands = {}\n",
    "            nonlocalBrands = {}\n",
    "        elif(self.productType == Products.Eggs.name):\n",
    "            localBrands = {}\n",
    "            nonlocalBrands ={}\n",
    "        elif(self.productType == Products.HeirloomTomatoes.name):\n",
    "            localBrands = {}\n",
    "            nonlocalBrands ={}    \n",
    "            #Sometimes it says it the name \n",
    "            if 'local' in self.Data['Product Type'].lower().replace(' ', ''): # convert to lowercase and remove spaces\n",
    "                self.Data['Local'] = 'Local'\n",
    "                return\n",
    "        #Add product brands here\n",
    "        else:\n",
    "            #Catch if no local/nonlocal brands are set for the product\n",
    "            return \n",
    "        if self.Data['Brand'] == None:\n",
    "            #If no brand was set we look at the product name\n",
    "            brand = self.Data['Product Type'].lower().replace(' ', '')\n",
    "        else:\n",
    "            brand = self.Data['Brand'].lower().replace(' ', '')\n",
    "        if brand in localBrands:\n",
    "            self.Data['Local'] = \"Local\"\n",
    "        elif brand in nonlocalBrands:\n",
    "            self.Data['Local'] = \"Non-local\"\n",
    "        else:\n",
    "           self.Data['Local'] = \"None Listed\"\n",
    "    \n",
    "    #For Hyvee there are multiple stores however I could not find a way to check each store\n",
    "    #This is something to be developed (improved upon) in the future\n",
    "    def setLocationalData(self):\n",
    "        self.Data['Address'] = 'NA'\n",
    "        self.Data['State'] = 'NA'\n",
    "        self.Data['City'] = 'NA'\n",
    "        self.Data['Zip Code'] = 'NA'\n",
    "\n",
    "# class DataCleaner():\n",
    "#     DataArray = []\n",
    "#     def cleanUp(self, item, url):\n",
    "#         self.DataArray = item\n",
    "#         if self.DataArray[3] == None:\n",
    "#             self.swap_elements(2, 3)\n",
    "#         self.DataArray.append(url)\n",
    "#         return self.DataArray\n",
    "    \n",
    "#     def swap_elements(self, idx1, idx2):\n",
    "#         # Make a copy of the input list to avoid modifying it\n",
    "#         new_lst = self.DataArray.copy()\n",
    "#         # Swap the elements at the two indices\n",
    "#         new_lst[idx1], new_lst[idx2] = new_lst[idx2], new_lst[idx1]\n",
    "#         self.DataArray = new_lst\n",
    "\n",
    "class HyveeSpider():\n",
    "    name = \"Hyvee\"  #The store name \n",
    "    spiderLogs = []         #The logs \n",
    "    skipped = []            #Skipped data \n",
    "\n",
    "    #These are methods that are available for your convences\n",
    "    def log(self, *args):\n",
    "        self.spiderLogs.append(('Logger:', args))\n",
    "        if self.LOGGER:\n",
    "            print('Logger:', *args)\n",
    "\n",
    "    def debug(self, *args):\n",
    "        self.spiderLogs.append(('Debug:', args))\n",
    "        if self.DEBUGGER:\n",
    "            print('Debug:', *args)\n",
    "    \n",
    "    def printer(self, *args):\n",
    "        self.spiderLogs.append(('Printer:', args))\n",
    "        print(*args)\n",
    "    \n",
    "    def printLogs(self):\n",
    "        print(\"\\n< --- Printing Logs --- >\\n\")\n",
    "        for entry in self.spiderLogs:\n",
    "            print(*entry)\n",
    "\n",
    "    def Logs_to_file(self, filename):\n",
    "        with open(filename, 'w') as file:\n",
    "            for log_entry in self.spiderLogs:\n",
    "                file.write('{} {}\\n'.format(log_entry[0], log_entry[1]))\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.DEBUGGER = False #The debugger switch to see whats going on. The Default is False\n",
    "        self.LOGGER = False #When you need to see everything that happends. The Default is False\n",
    "        self.attempts = 3 #The number of attempts the spider can retry if an error occurs. Default is 3\n",
    "        self.waitTime = 10 #The number of seconds WebDriver will wait. Default is 10\n",
    "        self.count = 0 #This saves the location of the url we are going through\n",
    "        self.runTime = 0 #Total time of extractions\n",
    "        self.totalRecoveries = 0 #Number of recoveries made while running\n",
    "        self.maxRetryCount = 100 #Number of retrys the javascript can make Defualt is 100\n",
    "        self.cleaner = DataCleaner() #Loads the cleaner\n",
    "        #Selenium needs a webdriver to work. I chose Firefox however you can do another if you need too\n",
    "        self.driver = webdriver.Firefox(service=FirefoxService(GeckoDriverManager().install(), log_path=path.devnull))\n",
    "        self.log(\"Driver started\")\n",
    "    \n",
    "    #This handles the restart in case we run into an error\n",
    "    def restart(self):\n",
    "        self.driver.quit()\n",
    "        self.driver = webdriver.Firefox(service=FirefoxService(GeckoDriverManager().install(), log_path=path.devnull))\n",
    "        self.log(\"Driver restarted\")\n",
    "    \n",
    "    #This starts the spider\n",
    "    def start_requests( self ):\n",
    "        self.runTime = time.time()\n",
    "        self.log(\"Loading from ProductsLoader Class\")\n",
    "        load = ProductsLoader() #Loads all products\n",
    "        self.dataFrames = load.DataFrames #Adds all dataframes\n",
    "        self.debug(\"Products Loaded and Data Frames Added\")\n",
    "        self.debug('\\n < --- Setup runtime is %s seconds --- >' % (time.time() - self.runTime))\n",
    "        self.totalRecoveries = 0 \n",
    "        #Sweeps through all products\n",
    "        for product in (Products):\n",
    "            result = self.requestExtraction(product)\n",
    "        #Adds the date that the data was scraped\n",
    "        currentDate = str(datetime(datetime.today().year, datetime.today().month, datetime.today().day))[:-8]\n",
    "        self.log(\"Exporting files\")\n",
    "        #Dataframes to CSV files\n",
    "        for df, product in zip(self.dataFrames, (Products)):\n",
    "            df.to_csv(currentDate + self.name +\" \" + product.name + \".csv\")\n",
    "            self.log('\\n', df.to_string())\n",
    "        self.debug('\\n < --- Total runtime took %s seconds with %d recoveries --- >' % (time.time() - self.runTime, self.totalRecoveries))\n",
    "        if len(self.skipped) != 0:\n",
    "            self.debug('\\n < -!- WARNING SKIPPED (' + str(len(self.skipped)) + ') DATA FOUND --->')\n",
    "        self.Logs_to_file(currentDate + self.name + ' Spider Logs.txt')\n",
    "        if len(self.skipped) > 0:\n",
    "            self.debug(self.skipped)\n",
    "            self.skipHandler(currentDate)      \n",
    "        self.driver.quit()\n",
    "\n",
    "    #This handles the extraction request for the inputed product \n",
    "    def requestExtraction(self, product):\n",
    "        self.count = 0\n",
    "        errors = 0\n",
    "        start = time.time()\n",
    "        self.debug(\"Starting \"+ product.name)    \n",
    "        for trying in range(self.attempts):\n",
    "            try:\n",
    "                self.makeRequest(product)\n",
    "                self.debug(product.name + \" Finished\")    \n",
    "                self.log('\\n< --- ' + product.name + ' scrape took %s seconds with %d recoveries --- >\\n' % ((time.time() - start), errors))\n",
    "                self.totalRecoveries += errors\n",
    "                return self.totalRecoveries\n",
    "            except Exception as e:\n",
    "                #Note sometimes the browser will closed unexpectedly and theres not we can do but restart the driver\n",
    "                errors += 1\n",
    "                self.debug(\"An error occurred:\", e)\n",
    "                self.debug(\"Recovering extraction and continueing\")\n",
    "                self.restart() \n",
    "        self.debug(product.name + \" Did not Finished after \" + str(self.attempts) + \" Time wasted: %s seconds\" % (time.time() - start))\n",
    "        self.totalRecoveries += errors\n",
    "        return self.totalRecoveries\n",
    "\n",
    "    #This handles the reqests for each url and adds the data to the dataframe\n",
    "    def makeRequest(self, product):\n",
    "        productUrls = product.value[1]\n",
    "        total = len(productUrls)\n",
    "        while self.count < total:\n",
    "            url = productUrls[self.count]\n",
    "            self.driver.get(url)\n",
    "            self.log(\"Making a request for: \", url)\n",
    "            item = []\n",
    "            time.sleep(1) # marionette Error Fix\n",
    "            for xpath in product.value[2]:\n",
    "                #Retrying the xpath given the number of attempts\n",
    "                for attempt in range(self.attempts):\n",
    "                    data = self.javascriptXpath(xpath[0])\n",
    "                    if data in {'empty', 'skip'}:\n",
    "                        #speical case in case you need it\n",
    "                        if len(xpath) == 3:\n",
    "                            if xpath[2]:\n",
    "                                #example would be when there is actually is a '' in the xpath\n",
    "                                self.debug(\"xpath marked as speical\")\n",
    "                                item.append(None)\n",
    "                                data = 'speical'\n",
    "                                break\n",
    "                        if xpath[1] and data == 'empty':    \n",
    "                            #this is where setting the xpath to optional comes in\n",
    "                            self.debug(\"xpath wasnt avaliable\")\n",
    "                            item.append(None)\n",
    "                            break\n",
    "                        self.debug(\"Missing item retrying\")\n",
    "                    else:  #Data found\n",
    "                        item.append(data)\n",
    "                        self.log(data + ' was added to the list for: ', url)\n",
    "                        break\n",
    "                if attempt == self.attempts:\n",
    "                    data = 'skip'\n",
    "                if data == 'skip':  #To help clean the data we skip the item with gaps of data \n",
    "                    self.debug(\"An Item has been skipped for: \", url)  \n",
    "                    item = ['SKIPPED']\n",
    "                    #Taking the product name  dataframe number and index added as well as the url \n",
    "                    #to retry for later \n",
    "                    #This could take time to do so we do this at the very end after we made the cvs files\n",
    "                    self.skipped.append([product, self.count, url])\n",
    "                    break\n",
    "            if 'SKIPPED' in item:\n",
    "                #No point in cleaning skipped items\n",
    "                items = ['SKIPPED']*(self.dataFrames[product.value[0]].shape[1] - 1)\n",
    "                items.append(url)\n",
    "            else:\n",
    "                #We call the DataCleaner class to handle the cleaning of the data\n",
    "                #Its best to clean the data before we add it to the data frame\n",
    "                self.debug('Data cleaning started: ', item)\n",
    "                items = self.cleaner.cleanUp(item, url)\n",
    "                self.debug('Data cleaning finished: ', item)\n",
    "            self.debug('Extracted: ', items)\n",
    "            self.dataFrames[product.value[0]].loc[len(self.dataFrames[product.value[0]])] = items                    \n",
    "            self.count += 1\n",
    "            self.printer(product.name + \" item added \", self.count, \" of \", total, \":  \", items)\n",
    "\n",
    "    #Collecting the data from the xpath in JavaScript is faster and results in fewer errors than doing it in python\n",
    "    #This is where selenium shines because we can both use JavaScript and render JavaScript websites\n",
    "    #and is the only reason why we use it instead of scrapy\n",
    "    def javascriptXpath(self, xpath):\n",
    "        # if the time expires it assumes xpath wasnt found in the page\n",
    "        try: \n",
    "            #Waits for page to load \n",
    "            ignored_exceptions=(NoSuchElementException,StaleElementReferenceException)\n",
    "            elements = WebDriverWait(self.driver, self.waitTime, ignored_exceptions=ignored_exceptions).until(EC.presence_of_all_elements_located((By.XPATH, xpath)))\n",
    "\n",
    "            # Runs the javascript and collects the text data from the inputed xpath\n",
    "            # We want to keep repeating if we get any of these outputs becasue the page is still \n",
    "            # loading and we dont want to skip or waste time. (for fast computers)\n",
    "            retrycount = 0\n",
    "            invalidOutputs = {\"error\", 'skip' \"$nan\", ''}\n",
    "            while retrycount < self.maxRetryCount :\n",
    "                text = self.driver.execute_script(\"\"\"\n",
    "                    const element = document.evaluate(arguments[0], document, null, XPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue;\n",
    "                    if (!element) {\n",
    "                        return 'skip';\n",
    "                    }\n",
    "                    return element.textContent.trim();\n",
    "                \"\"\", \n",
    "                xpath)\n",
    "                checkText = text.replace(\" \", \"\").lower()\n",
    "                if checkText in invalidOutputs:\n",
    "                    retrycount+=1\n",
    "                else:\n",
    "                    self.log(retrycount, \"xpath attempts for (\", text, \")\")\n",
    "                    return text\n",
    "            self.log(\"xpath attempts count met. Problematic text (\" + text + \") for \", xpath)\n",
    "            return 'skip'\n",
    "        except TimeoutException:\n",
    "            self.log('Could not find xpath for: ', xpath)\n",
    "            return 'empty'\n",
    "\n",
    "           \n",
    "\n",
    "    #This is here to hopefully fix skipped data\n",
    "    #Best case sinarios this will never be used\n",
    "    def skipHandler(self, currentDate):\n",
    "        corrections = 0\n",
    "        # skipped format\n",
    "        # [product name, DataFrame number, DataFrame index, url]\n",
    "        while len(self.skipped) != 0:\n",
    "            #each skip \n",
    "            for index, dataSkip in enumerate(self.skipped):\n",
    "                product = dataSkip[0]\n",
    "                #Limiting the Attempts to fix while avoiding bottlenecking the problem\n",
    "                for attempt in range(self.attempts*2):\n",
    "                    product = dataSkip[0]\n",
    "                    url = dataSkip[2]\n",
    "                    self.driver.get(url)\n",
    "                    self.log(\"Making a request for: \", url)\n",
    "                    item = []\n",
    "                    for xpath in product.value[2]:\n",
    "                        for attemptIn in range(self.attempts*2):\n",
    "                            data = self.javascriptXpath(xpath[0])\n",
    "                            if data in {'empty', 'skip'}:   \n",
    "                                if xpath[1] and data == 'empty':    \n",
    "                                    #this is where setting the xpath to optional comes in\n",
    "                                    self.debug(\"xpath wasnt avaliable\")\n",
    "                                    item.append(None)\n",
    "                                    break\n",
    "                                self.debug(\"Missing item retrying\")\n",
    "                            else:  #Data found\n",
    "                                item.append(data)\n",
    "                                self.log(data + ' was added to the list for: ', url)\n",
    "                                break\n",
    "                        if attemptIn == self.attempts*2:\n",
    "                            data = 'skip'\n",
    "                            break\n",
    "                if data == 'skip':  #To help clean the data we skip the item with gaps of data \n",
    "                    self.debug(\"Item still missing attempting other skipped for now\") \n",
    "                else:\n",
    "                    items = self.cleaner.cleanUp(item, url)\n",
    "                    self.dataFrames[dataSkip[1]].loc[dataSkip[2]] = items                    \n",
    "                    self.printer(\"Fixed \" + product.name + \" item: \", items)\n",
    "                    #To avoid infinite loops and never saving our data we save the file now\n",
    "                    self.dataFrames[product.value[0]].to_csv(currentDate + \"REPAIRED Gateway Market \" + product.name + \".csv\")\n",
    "                    self.debug('\\n < --- Total runtime with saving of repairs took %s seconds --- >' % (time.time() - self.runTime))\n",
    "                    self.Logs_to_file(currentDate + self.name + ' Spider REPAIR Logs.txt')\n",
    "                    #To avoid fixing fixed items we pop, mark, and break\n",
    "                    self.skipped.pop(index)\n",
    "                    corrections += 1\n",
    "                    break\n",
    "        self.debug('\\n < --- Total runtime with all repairs took %s seconds --- >' % (time.time() - self.runTime))\n",
    "        self.Logs_to_file(currentDate + self.name + ' spider COMPLETED REPAIR Logs.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start\n",
    "#DEBUG Switch\n",
    "SHOW = True\n",
    "\n",
    "#Spider setup\n",
    "spider = HyveeSpider()\n",
    "spider.LOGGER = True\n",
    "spider.DEBUGGER = True\n",
    "\n",
    "#Running the spider\n",
    "spider.start_requests()\n",
    "\n",
    "if(SHOW):\n",
    "    [print(dataFrame) for dataFrame in spider.dataFrames]\n",
    "    spider.printLogs()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSPG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
