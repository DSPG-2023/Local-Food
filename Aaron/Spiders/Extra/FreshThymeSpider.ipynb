{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.utils.log import configure_logging\n",
    "\n",
    "class FreshThymeSpider(scrapy.Spider):\n",
    "    name = 'Fresh Thyme Market Spider'\n",
    "\n",
    "    def start_requests( self ):\n",
    "        \n",
    "        carrotsUrls = ['https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=carrots&take=48&f=Category%3AFresh+Vegetables',\n",
    "                       'https://ww2.freshthyme.com/sm/planning/rsid/952/results?q=carrots&take=48&f=Category%3AFresh+Vegetables']\n",
    "        for url in carrotsUrls:\n",
    "            yield scrapy.Request( url = url, callback = self.cardsParse, meta={'type': 0})\n",
    "        \n",
    "        greenOnionsUrls = ['https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=green+Onions&take=48&f=Category%3AFresh+Vegetables',\n",
    "                           'https://ww2.freshthyme.com/sm/planning/rsid/952/results?q=green+Onions&take=48&f=Category%3AFresh+Vegetables']\n",
    "        for url in greenOnionsUrls:\n",
    "            yield scrapy.Request( url = url, callback = self.cardsParse, meta={'type': 1})\n",
    "        \n",
    "        potatoesUrls = ['https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=potato&take=48&f=Category%3AFresh+Vegetables',\n",
    "                        'https://ww2.freshthyme.com/sm/planning/rsid/952/results?q=potato&take=48&f=Category%3AFresh+Vegetables']\n",
    "        for url in potatoesUrls:\n",
    "            yield scrapy.Request( url = url, callback = self.cardsParse, meta={'type': 2})\n",
    "        \n",
    "        spinachUrls = ['https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=spinach&take=48&f=Category%3AFresh+Vegetables',\n",
    "                       'https://ww2.freshthyme.com/sm/planning/rsid/952/results?q=spinach&take=48&f=Category%3AFresh+Vegetables']\n",
    "        for url in spinachUrls:\n",
    "            yield scrapy.Request( url = url, callback = self.cardsParse, meta={'type': 3})\n",
    "        \n",
    "        lettuceUrls = ['https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=lettuce',\n",
    "                       'https://ww2.freshthyme.com/sm/planning/rsid/952/results?q=lettuce']\n",
    "        for url in lettuceUrls:\n",
    "            yield scrapy.Request( url = url, callback = self.cardsParse, meta={'type': 4})\n",
    "        \n",
    "        #Dont know\n",
    "        slicersTomatoesUrls = []\n",
    "        for url in slicersTomatoesUrls:\n",
    "            yield scrapy.Request( url = url, callback = self.cardsParse, meta={'type': 5})\n",
    "        \n",
    "        #Heirloom Tomatoes part\n",
    "        hirloomTomatoUrls = ['https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=heirloom%20tomatoes',\n",
    "                             'https://ww2.freshthyme.com/sm/planning/rsid/952/results?q=heirloom%20tomatoes']\n",
    "\n",
    "        for url in hirloomTomatoUrls:\n",
    "            yield scrapy.Request( url = url, callback = self.cardsParse, meta={'type': 6})\n",
    "  \n",
    "        cherryTomatoesUrls = ['https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Tomatoes+cherry&take=48&f=Category%3AFresh+Vegetables',\n",
    "                              'https://ww2.freshthyme.com/sm/planning/rsid/952/results?q=Tomatoes+cherry&take=48&f=Category%3AFresh+Vegetables']\n",
    "        for url in cherryTomatoesUrls:\n",
    "            yield scrapy.Request( url = url, callback = self.cardsParse, meta={'type': 7})\n",
    "\n",
    "        strawberriesUrls = ['https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Strawberries&take=48&f=Category%3AFresh+Fruits',\n",
    "                            'https://ww2.freshthyme.com/sm/planning/rsid/952/results?q=Strawberries&take=48&f=Category%3AFresh+Fruits']\n",
    "        for url in strawberriesUrls:\n",
    "            yield scrapy.Request( url = url, callback = self.cardsParse, meta={'type': 8})\n",
    "        \n",
    "        raspberriesUrls = ['https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=raspberries&take=48&f=Category%3AFresh+Fruits',\n",
    "                           'https://ww2.freshthyme.com/sm/planning/rsid/952/results?q=raspberries&take=48&f=Category%3AFresh+Fruits']\n",
    "        for url in raspberriesUrls:\n",
    "            yield scrapy.Request( url = url, callback = self.cardsParse, meta={'type': 9})\n",
    "\n",
    "        mushroomsUrls = ['https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=mushrooms&take=48&f=Category%3AFresh+Vegetables',\n",
    "                         'https://ww2.freshthyme.com/sm/planning/rsid/952/results?q=mushrooms&take=48&f=Category%3AFresh+Vegetables']\n",
    "        for url in mushroomsUrls:\n",
    "            yield scrapy.Request( url = url, callback = self.cardsParse, meta={'type': 10})\n",
    "        \n",
    "        #Egg Scraper part\n",
    "        eggUrls = ['https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Eggs&take=48&f=Category%3AEggs',\n",
    "                   'https://ww2.freshthyme.com/sm/planning/rsid/952/results?q=Eggs&take=48&f=Category%3AEggs']\n",
    "        for url in eggUrls:\n",
    "            yield scrapy.Request( url = url, callback = self.cardsParse, meta={'type': 11})\n",
    "        \n",
    "        chickenWholeUrls = ['https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=chicken+Whole&take=48&f=Category%3AAll+Natural+Poultry',\n",
    "                            'https://ww2.freshthyme.com/sm/planning/rsid/952/results?q=chicken+Whole&take=48&f=Category%3AAll+Natural+Poultry']\n",
    "        for url in chickenWholeUrls:\n",
    "            yield scrapy.Request( url = url, callback = self.cardsParse, meta={'type': 12})\n",
    "        \n",
    "        #Dont know\n",
    "        chickenHalfUrls = []\n",
    "        for url in chickenHalfUrls:\n",
    "            yield scrapy.Request( url = url, callback = self.cardsParse, meta={'type': 13})\n",
    "\n",
    "        steakUrls = ['https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=steak+beef&take=48',\n",
    "                     'https://ww2.freshthyme.com/sm/planning/rsid/952/results?q=steak+beef&take=48']\n",
    "        for url in steakUrls:\n",
    "            yield scrapy.Request( url = url, callback = self.cardsParse, meta={'type': 14})\n",
    "        \n",
    "        groundBeefUrls = [\"https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=ground%20beef\",\n",
    "                          \"https://ww2.freshthyme.com/sm/planning/rsid/952/results?q=ground%20beef\"]\n",
    "        for url in groundBeefUrls:\n",
    "            yield scrapy.Request( url = url, callback = self.cardsParse, meta={'type': 15})\n",
    "        \n",
    "        #Bacon Scraper part\n",
    "        baconUrls = ['https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage',\n",
    "                     'https://ww2.freshthyme.com/sm/planning/rsid/952/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage']\n",
    "        for url in baconUrls:\n",
    "            yield scrapy.Request( url = url, callback = self.cardsParse, meta={'type': 16})\n",
    "        \n",
    "        porkChopsUrls = ['https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=pork Chops',\n",
    "                         'https://ww2.freshthyme.com/sm/planning/rsid/952/results?q=pork Chops']\n",
    "        for url in porkChopsUrls:\n",
    "            yield scrapy.Request( url = url, callback = self.cardsParse, meta={'type': 17})\n",
    "            \n",
    "        allTomatoesUrl =['https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Tomatoes&take=48&f=Category%3AFresh+Vegetables',\n",
    "                         'https://ww2.freshthyme.com/sm/planning/rsid/952/results?q=Tomatoes&take=48&f=Category%3AFresh+Vegetables']\n",
    "        for url in allTomatoesUrl:\n",
    "            yield scrapy.Request( url = url, callback = self.cardsParse, meta={'type': 18})\n",
    "        \n",
    "\n",
    "    def cardsParse(self, response):\n",
    "        #Failsafe for links\n",
    "        try:\n",
    "            #grabs the store location\n",
    "            storeXpath = '//*[contains(@class,\"HeaderSubtitle\")]/text()'\n",
    "            store = response.xpath(storeXpath).extract_first()\n",
    "            #grabs all cards from list and saves the link to follow\n",
    "            xpath = '//*[contains(@class,\"Listing\")]/div/a/@href'\n",
    "            listCards = response.xpath(xpath)\n",
    "            for url in listCards:\n",
    "                yield response.follow( url = url, callback = self.itemParse, meta={'store': store, 'type': response.meta.get('type')} )\n",
    "        except AttributeError:\n",
    "           pass\n",
    "    \n",
    "    def itemParse(self, response):\n",
    "        #xpaths to extract \n",
    "        nameXpath = '//*[contains(@class, \"PdpInfoTitle\")]/text()'\n",
    "        priceXpath = '//*[contains(@class, \"PdpMainPrice\")]/text()'\n",
    "        prevPriceXpath = '//*[contains(@class, \"PdpPreviousPrice\")]/text()'\n",
    "        unitPriceXpath = '//*[contains(@class, \"PdpUnitPrice\")]/text()'\n",
    "        itemType = response.meta.get('type')\n",
    "        DataFrame[itemType].loc[len(DataFrame[itemType])] = [response.xpath(nameXpath).extract_first(),\n",
    "                                                             response.xpath(priceXpath).extract_first(), \n",
    "                                                             response.xpath(prevPriceXpath).extract_first(), \n",
    "                                                             response.xpath(unitPriceXpath).extract_first(), \n",
    "                                                             response.meta.get('store'),\n",
    "                                                             response.url]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start\n",
    "#DEBUG Switch\n",
    "DEBUG = False\n",
    "\n",
    "#Data frames\n",
    "DataFrame = [\n",
    "    pd.DataFrame(columns=['Carrots', 'Current Price', 'Sale', 'Unit Price', 'Store Location', 'Url']),\n",
    "    pd.DataFrame(columns=['Green Onions', 'Current Price', 'Sale', 'Unit Price', 'Store Location', 'Url']),\n",
    "    pd.DataFrame(columns=['Potatoes', 'Current Price', 'Sale', 'Unit Price', 'Store Location', 'Url']),\n",
    "    pd.DataFrame(columns=['Spinach', 'Current Price', 'Sale', 'Unit Price', 'Store Location', 'Url']),\n",
    "    pd.DataFrame(columns=['Lettuce', 'Current Price', 'Sale', 'Unit Price', 'Store Location', 'Url']),\n",
    "    pd.DataFrame(columns=['Tomato (Slicers)', 'Current Price', 'Sale', 'Unit Price', 'Store Location', 'Url']),\n",
    "    pd.DataFrame(columns=['Tomato (Heirloom)', 'Current Price', 'Sale', 'Unit Price', 'Store Location', 'Url']),\n",
    "    pd.DataFrame(columns=['Tomato (Cherry)', 'Current Price', 'Sale', 'Unit Price', 'Store Location', 'Url']),\n",
    "    pd.DataFrame(columns=['Strawberries', 'Current Price', 'Sale', 'Unit Price', 'Store Location', 'Url']),\n",
    "    pd.DataFrame(columns=['Raspberries', 'Current Price', 'Sale', 'Unit Price', 'Store Location', 'Url']),\n",
    "    pd.DataFrame(columns=['Mushrooms', 'Current Price', 'Sale', 'Unit Price', 'Store Location', 'Url']),\n",
    "    pd.DataFrame(columns=['Eggs', 'Current Price', 'Sale', 'Unit Price', 'Store Location', 'Url']),\n",
    "    pd.DataFrame(columns=['Chicken (Whole)', 'Current Price', 'Sale', 'Unit Price', 'Store Location', 'Url']),\n",
    "    pd.DataFrame(columns=['Chicken (Half)', 'Current Price', 'Sale', 'Unit Price', 'Store Location', 'Url']),\n",
    "    pd.DataFrame(columns=['Beef (Steak)', 'Current Price', 'Sale', 'Unit Price', 'Store Location', 'Url']),\n",
    "    pd.DataFrame(columns=['Beef (Ground)', 'Current Price', 'Sale', 'Unit Price', 'Store Location', 'Url']),\n",
    "    pd.DataFrame(columns=['Pork (Bacon)', 'Current Price', 'Sale', 'Unit Price', 'Store Location', 'Url']),\n",
    "    pd.DataFrame(columns=['Pork (Pork Chops)', 'Current Price', 'Sale', 'Unit Price', 'Store Location', 'Url']),\n",
    "    pd.DataFrame(columns=['All Tomatoes', 'Current Price', 'Sale', 'Unit Price', 'Store Location', 'Url'])\n",
    "]\n",
    "\n",
    "DataName = [\n",
    "    \"Fresh Thyme Carrots.csv\",\n",
    "    \"Fresh Thyme Green Onions.csv\",\n",
    "    \"Fresh Thyme Potatoes.csv\",\n",
    "    \"Fresh Thyme Spinach.csv\",\n",
    "    \"Fresh Thyme Lettuce.csv\",\n",
    "    \"Fresh Thyme Tomato (Slicers).csv\",\n",
    "    \"Fresh Thyme Tomato (Heirloom).csv\",\n",
    "    \"Fresh Thyme Tomato (Cherry).csv\",\n",
    "    \"Fresh Thyme Strawberries.csv\",\n",
    "    \"Fresh Thyme Raspberries.csv\",\n",
    "    \"Fresh Thyme Mushrooms.csv\",\n",
    "    \"Fresh Thyme Eggs.csv\",\n",
    "    \"Fresh Thyme Chicken (Whole).csv\",\n",
    "    \"Fresh Thyme Chicken (Half).csv\",\n",
    "    \"Fresh Thyme Beef (Steak).csv\",\n",
    "    \"Fresh Thyme Beef (Ground).csv\",\n",
    "    \"Fresh Thyme Pork (Bacon).csv\",\n",
    "    \"Fresh Thyme Pork (Pork Chops).csv\",\n",
    "    \"Fresh Thyme All Tomatoes.csv\"\n",
    "]\n",
    "\n",
    "\n",
    "if(DEBUG):\n",
    "    #To see the inner mechanics of the spider\n",
    "    configure_logging()\n",
    "\n",
    "#This is to start the spider\n",
    "process = CrawlerProcess()\n",
    "process.crawl(FreshThymeSpider)\n",
    "process.start()\n",
    "process.stop()\n",
    "\n",
    "if(DEBUG):\n",
    "    #To see the outputs\n",
    "    for data in DataFrame:\n",
    "        print(data)\n",
    "\n",
    "#Adds the date that the data was scraped\n",
    "currentDate = str(datetime(datetime.today().year, datetime.today().month, datetime.today().day))[:-8]\n",
    "#To CSV files\n",
    "for dataIndex, name in enumerate(DataName):\n",
    "    DataFrame[dataIndex].to_csv(currentDate + name, index=False)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSPG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
