{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.utils.log import configure_logging\n",
    "from DSPG_Products import Products #Imports the products to be processed\n",
    "from DSPG_Cleaner import DataCleaner # This is to handle the cleaning of data\n",
    "from DSPG_SpiderErrors import DataFormatingError\n",
    "\n",
    "class FreshThymeSpider(scrapy.Spider):\n",
    "    name = 'Fresh Thyme Market Spider'\n",
    "\n",
    "    def start_requests( self ):\n",
    "        #Bacon Scraper part\n",
    "        bacon_urls = ['https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage',\n",
    "                      'https://ww2.freshthyme.com/sm/planning/rsid/952/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage']\n",
    "        for url in bacon_urls:\n",
    "            yield scrapy.Request( url = url, callback = self.cardsParse, meta={'index': 0, 'url': url})\n",
    "\n",
    "        # #Egg Scraper part\n",
    "        egg_urls = ['https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Eggs&take=48&f=Category%3AEggs',\n",
    "                    'https://ww2.freshthyme.com/sm/planning/rsid/952/results?q=Eggs&take=48&f=Category%3AEggs']\n",
    "        for url in egg_urls:\n",
    "            yield scrapy.Request( url = url, callback = self.cardsParse, meta={'index': 1, 'url': url})\n",
    "\n",
    "        #Heirloom Tomatoes part\n",
    "        heirloomTomato_urls = ['https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=heirloom%20Tomatoes',\n",
    "                               'https://ww2.freshthyme.com/sm/planning/rsid/952/results?q=heirloom%20Tomatoes']\n",
    "        for url in heirloomTomato_urls:\n",
    "            yield scrapy.Request( url = url, callback = self.cardsParse, meta={'index': 2, 'url': url})\n",
    "\n",
    "        # All Tomatoes\n",
    "        allTomatoesUrl =['https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Tomatoes&take=48&f=Category%3AFresh+Vegetables',\n",
    "                         'https://ww2.freshthyme.com/sm/planning/rsid/952/results?q=Tomatoes&take=48&f=Category%3AFresh+Vegetables']\n",
    "        for url in allTomatoesUrl:\n",
    "            yield scrapy.Request( url = url, callback = self.cardsParse, meta={'index': 3, 'url': url})\n",
    "\n",
    "    def cardsParse(self, response):\n",
    "        #Failsafe for links\n",
    "        try:\n",
    "            #grabs the store location\n",
    "            storeXpath = '//*[contains(@class,\"HeaderSubtitle\")]/text()'\n",
    "            store = response.xpath(storeXpath).extract_first()\n",
    "            #grabs all cards from list and saves the link to follow\n",
    "            xpath = '//*[contains(@class,\"Listing\")]/div/a/@href'\n",
    "            listCards = response.xpath(xpath)\n",
    "            for url in listCards:\n",
    "                yield response.follow( url = url, callback = self.itemParse, meta={'store': store, 'index': response.meta.get('index'), 'url': response.meta.get('url')} )\n",
    "        except AttributeError:\n",
    "           pass\n",
    "    \n",
    "    def itemParse(self, response):\n",
    "        #xpaths to extract \n",
    "        nameXpath = '//*[contains(@class, \"PdpInfoTitle\")]/text()'\n",
    "        priceXpath = '//*[contains(@class, \"PdpMainPrice\")]/text()'\n",
    "        prevPriceXpath = '//*[contains(@class, \"PdpPreviousPrice\")]/text()'\n",
    "        name = response.xpath(nameXpath).extract_first()\n",
    "        price = response.xpath(priceXpath).extract_first()\n",
    "        sale = response.xpath(prevPriceXpath).extract_first()\n",
    "        url = response.meta.get('url')\n",
    "        clean = DataCleaner()\n",
    "        #Adding the data to data frame\n",
    "        indexFrame = response.meta.get('index')\n",
    "        if(indexFrame == 0):\n",
    "            #We only want bacon\n",
    "            if 'bacon' not in name.lower().replace(' ', ''):\n",
    "                return\n",
    "            clean.LoadDataSet(0, url)\n",
    "            clean.Data['Product Type'] = name\n",
    "            clean.Data['Current Price'] = price\n",
    "            clean.Data['Orignal Price'] = sale\n",
    "            clean.baconModifications()\n",
    "        elif(indexFrame == 1):\n",
    "            string = name.lower().replace(' ', '')\n",
    "            string = string.split('-')\n",
    "            checkString = string[len(string)-1]\n",
    "            #We only want eggs\n",
    "            if 'each' not in checkString or 'cooked' in name.lower().replace(' ', '') or 'boiled' in name.lower().replace(' ', ''):\n",
    "                return\n",
    "            clean.LoadDataSet(1, url)\n",
    "            if '1each' in checkString or '12each' in checkString:\n",
    "                clean.Data['True Amount'] = f\"{1} dz\"\n",
    "                clean.Data['Amount in dz'] = 1.0\n",
    "            elif '1.5each' in checkString:\n",
    "                clean.Data['True Amount'] = f\"{1.5} dz\"\n",
    "                clean.Data['Amount in dz'] = 1.5\n",
    "            clean.Data['Product Type'] = name\n",
    "            clean.Data['Current Price'] = price\n",
    "            clean.Data['Orignal Price'] = sale\n",
    "        elif(indexFrame == 2 or indexFrame == 3):\n",
    "            clean.LoadDataSet(indexFrame, url)\n",
    "            clean.Data['Product Type'] = name\n",
    "            clean.Data['Current Price'] = price\n",
    "            clean.Data['Orignal Price'] = sale\n",
    "            clean.tomatoesModifications(None)\n",
    "        #Add more products here\n",
    "        else:\n",
    "            raise DataFormatingError(indexFrame)\n",
    "        clean = self.setLocationalData(clean, response.meta.get('store'))\n",
    "        clean.cleanPricing()\n",
    "        if(indexFrame < len(DataFrame)):\n",
    "            DataFrame[indexFrame].loc[len(DataFrame[indexFrame])] = list(clean.Data.values())\n",
    "        else:\n",
    "            raise DataFormatingError(indexFrame)\n",
    "        \n",
    "    def setLocationalData(self, clean, storeLocation):\n",
    "        store = storeLocation.lower().replace(' ', '')\n",
    "        if 'westdesmoines' in store:\n",
    "            clean.Data['Address'] = '2900 University Ave. Suite 240'\n",
    "            clean.Data['State'] = 'IA'\n",
    "            clean.Data['City'] = 'West Des Moines'\n",
    "            clean.Data['Zip Code'] = '50266'    \n",
    "        elif 'davenport' in store:\n",
    "            clean.Data['Address'] = '2130 E. Kimberly Rd.'\n",
    "            clean.Data['State'] = 'IA'\n",
    "            clean.Data['City'] = 'Davenport'\n",
    "            clean.Data['Zip Code'] = '52807'    \n",
    "        return clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start\n",
    "product = Products()\n",
    "DataFrame = product.ProductDataFrames\n",
    "\n",
    "DEBUG = False\n",
    "if(DEBUG):\n",
    "    configure_logging()\n",
    "\n",
    "#This is to start the spider\n",
    "process = CrawlerProcess()\n",
    "process.crawl(FreshThymeSpider)\n",
    "process.start()\n",
    "process.stop()\n",
    "\n",
    "currentDate = str(datetime(datetime.today().year, datetime.today().month, datetime.today().day))[:-8]\n",
    "folderPath = currentDate + \"Data\"\n",
    "if not os.path.exists(folderPath):\n",
    "    os.makedirs(folderPath)\n",
    "\n",
    "#To CSV files\n",
    "for index, frame in enumerate(DataFrame):\n",
    "    fileName = currentDate + \"Fresh Thyme \" + product.ProductList[index][1] + \".csv\"\n",
    "    frame.to_csv(os.path.join(folderPath, fileName), index=False)\n",
    "\n",
    "if(DEBUG):\n",
    "    #To see the outputs\n",
    "    for data in DataFrame:\n",
    "        print(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSPG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
